{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73b38519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.0.1\n",
      "1.11.3\n",
      "1.23.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dylanseychell/.pyenv/versions/3.10.0/envs/py310/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.11.0+cu115 True\n"
     ]
    }
   ],
   "source": [
    "import yaml, scipy, os, numpy\n",
    "print(yaml.__version__)\n",
    "print(scipy.__version__)\n",
    "print(numpy.__version__)\n",
    "\n",
    "import torch \n",
    "use_cuda = torch. cuda. is_available()\n",
    "\n",
    "print(torch.__version__, torch.cuda.is_available())\n",
    "\n",
    "import tkinter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dcac9ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import subprocess\n",
    "HOME_PATH='/mnt/d/Justine/uni'\n",
    "\n",
    "def process_images(directory, directory_output, config, checkpoint):\n",
    "  for filename in os.listdir(directory):\n",
    "    f = os.path.join(directory, filename)\n",
    "    # checking if it is a file\n",
    "    if os.path.isfile(f):\n",
    "        print(\"Processing file: \" + f)\n",
    "        filepath, file_extension = os.path.splitext(f)\n",
    "        filename = filepath.split(\"/\")[-1]\n",
    "        full_directory_output = directory_output + '/' + filename\n",
    "\n",
    "        # Check if directory is available\n",
    "        isExist = os.path.exists(full_directory_output)\n",
    "        if not isExist:\n",
    "          os.makedirs(full_directory_output)\n",
    "          print(\"Created directory: \" + full_directory_output)\n",
    "\n",
    "        # Check if results are available\n",
    "        isExist = os.path.exists(full_directory_output + '/alphapose-results.json')\n",
    "        #if not isExist:\n",
    "          #cmd = 'python scripts/demo_inference.py --cfg {} --checkpoint {} --video {} --outdir \"{}\" --format open --save_video'\n",
    "        cmd = 'python {}/AlphaPose/scripts/demo_inference.py --cfg {} --checkpoint {} --image {} --outdir \"{}\" --save_img'\n",
    "        cmd = cmd.format(HOME_PATH, config, checkpoint, f, full_directory_output)\n",
    "        print(cmd)\n",
    "\n",
    "        p = subprocess.Popen(cmd, stdout=subprocess.PIPE, shell=True)\n",
    "        out, err = p.communicate()\n",
    "\n",
    "\n",
    "def process_images_folder(directory, directory_output, config, checkpoint):\n",
    "    cmd = 'python {}/AlphaPose/scripts/demo_inference.py --cfg {} --checkpoint {} --indir {} --outdir \"{}\" --save_img'\n",
    "    cmd = cmd.format(HOME_PATH, config, checkpoint, directory, directory_output)\n",
    "    print(cmd)\n",
    "\n",
    "    p = subprocess.Popen(cmd, stdout=subprocess.PIPE, shell=True)\n",
    "    out, err = p.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /mnt/d/Justine/uni/data/coco/val2017/000000000139.jpg\n",
      "Created directory: /mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000000139\n",
      "python /mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py --cfg /mnt/d/Justine/uni/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml --checkpoint /mnt/d/Justine/uni/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth --indir /mnt/d/Justine/uni/data/coco/val2017/000000000139.jpg --outdir \"/mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000000139\" --save_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:36:36 [DEBUG]: Loaded backend agg version v2.2.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 163, in <module>\n",
      "    mode, input_source = check_input()\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 137, in check_input\n",
      "    im_names = natsort.natsorted(im_names)\n",
      "UnboundLocalError: local variable 'im_names' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /mnt/d/Justine/uni/data/coco/val2017/000000000285.jpg\n",
      "Created directory: /mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000000285\n",
      "python /mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py --cfg /mnt/d/Justine/uni/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml --checkpoint /mnt/d/Justine/uni/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth --indir /mnt/d/Justine/uni/data/coco/val2017/000000000285.jpg --outdir \"/mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000000285\" --save_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:36:39 [DEBUG]: Loaded backend agg version v2.2.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 163, in <module>\n",
      "    mode, input_source = check_input()\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 137, in check_input\n",
      "    im_names = natsort.natsorted(im_names)\n",
      "UnboundLocalError: local variable 'im_names' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /mnt/d/Justine/uni/data/coco/val2017/000000000632.jpg\n",
      "Created directory: /mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000000632\n",
      "python /mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py --cfg /mnt/d/Justine/uni/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml --checkpoint /mnt/d/Justine/uni/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth --indir /mnt/d/Justine/uni/data/coco/val2017/000000000632.jpg --outdir \"/mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000000632\" --save_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:36:41 [DEBUG]: Loaded backend agg version v2.2.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 163, in <module>\n",
      "    mode, input_source = check_input()\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 137, in check_input\n",
      "    im_names = natsort.natsorted(im_names)\n",
      "UnboundLocalError: local variable 'im_names' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /mnt/d/Justine/uni/data/coco/val2017/000000000724.jpg\n",
      "Created directory: /mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000000724\n",
      "python /mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py --cfg /mnt/d/Justine/uni/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml --checkpoint /mnt/d/Justine/uni/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth --indir /mnt/d/Justine/uni/data/coco/val2017/000000000724.jpg --outdir \"/mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000000724\" --save_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:36:43 [DEBUG]: Loaded backend agg version v2.2.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 163, in <module>\n",
      "    mode, input_source = check_input()\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 137, in check_input\n",
      "    im_names = natsort.natsorted(im_names)\n",
      "UnboundLocalError: local variable 'im_names' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /mnt/d/Justine/uni/data/coco/val2017/000000000776.jpg\n",
      "Created directory: /mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000000776\n",
      "python /mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py --cfg /mnt/d/Justine/uni/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml --checkpoint /mnt/d/Justine/uni/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth --indir /mnt/d/Justine/uni/data/coco/val2017/000000000776.jpg --outdir \"/mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000000776\" --save_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:36:46 [DEBUG]: Loaded backend agg version v2.2.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 163, in <module>\n",
      "    mode, input_source = check_input()\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 137, in check_input\n",
      "    im_names = natsort.natsorted(im_names)\n",
      "UnboundLocalError: local variable 'im_names' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /mnt/d/Justine/uni/data/coco/val2017/000000000785.jpg\n",
      "Created directory: /mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000000785\n",
      "python /mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py --cfg /mnt/d/Justine/uni/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml --checkpoint /mnt/d/Justine/uni/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth --indir /mnt/d/Justine/uni/data/coco/val2017/000000000785.jpg --outdir \"/mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000000785\" --save_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:36:48 [DEBUG]: Loaded backend agg version v2.2.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 163, in <module>\n",
      "    mode, input_source = check_input()\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 137, in check_input\n",
      "    im_names = natsort.natsorted(im_names)\n",
      "UnboundLocalError: local variable 'im_names' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /mnt/d/Justine/uni/data/coco/val2017/000000000802.jpg\n",
      "Created directory: /mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000000802\n",
      "python /mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py --cfg /mnt/d/Justine/uni/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml --checkpoint /mnt/d/Justine/uni/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth --indir /mnt/d/Justine/uni/data/coco/val2017/000000000802.jpg --outdir \"/mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000000802\" --save_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:36:50 [DEBUG]: Loaded backend agg version v2.2.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 163, in <module>\n",
      "    mode, input_source = check_input()\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 137, in check_input\n",
      "    im_names = natsort.natsorted(im_names)\n",
      "UnboundLocalError: local variable 'im_names' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /mnt/d/Justine/uni/data/coco/val2017/000000000872.jpg\n",
      "Created directory: /mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000000872\n",
      "python /mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py --cfg /mnt/d/Justine/uni/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml --checkpoint /mnt/d/Justine/uni/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth --indir /mnt/d/Justine/uni/data/coco/val2017/000000000872.jpg --outdir \"/mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000000872\" --save_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:36:52 [DEBUG]: Loaded backend agg version v2.2.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 163, in <module>\n",
      "    mode, input_source = check_input()\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 137, in check_input\n",
      "    im_names = natsort.natsorted(im_names)\n",
      "UnboundLocalError: local variable 'im_names' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /mnt/d/Justine/uni/data/coco/val2017/000000000885.jpg\n",
      "Created directory: /mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000000885\n",
      "python /mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py --cfg /mnt/d/Justine/uni/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml --checkpoint /mnt/d/Justine/uni/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth --indir /mnt/d/Justine/uni/data/coco/val2017/000000000885.jpg --outdir \"/mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000000885\" --save_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:36:55 [DEBUG]: Loaded backend agg version v2.2.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 163, in <module>\n",
      "    mode, input_source = check_input()\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 137, in check_input\n",
      "    im_names = natsort.natsorted(im_names)\n",
      "UnboundLocalError: local variable 'im_names' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /mnt/d/Justine/uni/data/coco/val2017/000000001000.jpg\n",
      "Created directory: /mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000001000\n",
      "python /mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py --cfg /mnt/d/Justine/uni/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml --checkpoint /mnt/d/Justine/uni/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth --indir /mnt/d/Justine/uni/data/coco/val2017/000000001000.jpg --outdir \"/mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000001000\" --save_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:36:57 [DEBUG]: Loaded backend agg version v2.2.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 163, in <module>\n",
      "    mode, input_source = check_input()\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 137, in check_input\n",
      "    im_names = natsort.natsorted(im_names)\n",
      "UnboundLocalError: local variable 'im_names' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /mnt/d/Justine/uni/data/coco/val2017/000000001268.jpg\n",
      "Created directory: /mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000001268\n",
      "python /mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py --cfg /mnt/d/Justine/uni/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml --checkpoint /mnt/d/Justine/uni/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth --indir /mnt/d/Justine/uni/data/coco/val2017/000000001268.jpg --outdir \"/mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000001268\" --save_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:36:59 [DEBUG]: Loaded backend agg version v2.2.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 163, in <module>\n",
      "    mode, input_source = check_input()\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 137, in check_input\n",
      "    im_names = natsort.natsorted(im_names)\n",
      "UnboundLocalError: local variable 'im_names' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /mnt/d/Justine/uni/data/coco/val2017/000000001296.jpg\n",
      "Created directory: /mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000001296\n",
      "python /mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py --cfg /mnt/d/Justine/uni/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml --checkpoint /mnt/d/Justine/uni/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth --indir /mnt/d/Justine/uni/data/coco/val2017/000000001296.jpg --outdir \"/mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000001296\" --save_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:37:02 [DEBUG]: Loaded backend agg version v2.2.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 163, in <module>\n",
      "    mode, input_source = check_input()\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 137, in check_input\n",
      "    im_names = natsort.natsorted(im_names)\n",
      "UnboundLocalError: local variable 'im_names' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /mnt/d/Justine/uni/data/coco/val2017/000000001353.jpg\n",
      "Created directory: /mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000001353\n",
      "python /mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py --cfg /mnt/d/Justine/uni/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml --checkpoint /mnt/d/Justine/uni/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth --indir /mnt/d/Justine/uni/data/coco/val2017/000000001353.jpg --outdir \"/mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000001353\" --save_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:37:04 [DEBUG]: Loaded backend agg version v2.2.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 163, in <module>\n",
      "    mode, input_source = check_input()\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 137, in check_input\n",
      "    im_names = natsort.natsorted(im_names)\n",
      "UnboundLocalError: local variable 'im_names' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /mnt/d/Justine/uni/data/coco/val2017/000000001425.jpg\n",
      "Created directory: /mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000001425\n",
      "python /mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py --cfg /mnt/d/Justine/uni/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml --checkpoint /mnt/d/Justine/uni/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth --indir /mnt/d/Justine/uni/data/coco/val2017/000000001425.jpg --outdir \"/mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000001425\" --save_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:37:06 [DEBUG]: Loaded backend agg version v2.2.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 163, in <module>\n",
      "    mode, input_source = check_input()\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 137, in check_input\n",
      "    im_names = natsort.natsorted(im_names)\n",
      "UnboundLocalError: local variable 'im_names' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /mnt/d/Justine/uni/data/coco/val2017/000000001490.jpg\n",
      "Created directory: /mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000001490\n",
      "python /mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py --cfg /mnt/d/Justine/uni/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml --checkpoint /mnt/d/Justine/uni/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth --indir /mnt/d/Justine/uni/data/coco/val2017/000000001490.jpg --outdir \"/mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000001490\" --save_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:37:09 [DEBUG]: Loaded backend agg version v2.2.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 163, in <module>\n",
      "    mode, input_source = check_input()\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 137, in check_input\n",
      "    im_names = natsort.natsorted(im_names)\n",
      "UnboundLocalError: local variable 'im_names' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /mnt/d/Justine/uni/data/coco/val2017/000000001503.jpg\n",
      "Created directory: /mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000001503\n",
      "python /mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py --cfg /mnt/d/Justine/uni/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml --checkpoint /mnt/d/Justine/uni/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth --indir /mnt/d/Justine/uni/data/coco/val2017/000000001503.jpg --outdir \"/mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000001503\" --save_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:37:11 [DEBUG]: Loaded backend agg version v2.2.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 163, in <module>\n",
      "    mode, input_source = check_input()\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 137, in check_input\n",
      "    im_names = natsort.natsorted(im_names)\n",
      "UnboundLocalError: local variable 'im_names' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /mnt/d/Justine/uni/data/coco/val2017/000000001532.jpg\n",
      "Created directory: /mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000001532\n",
      "python /mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py --cfg /mnt/d/Justine/uni/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml --checkpoint /mnt/d/Justine/uni/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth --indir /mnt/d/Justine/uni/data/coco/val2017/000000001532.jpg --outdir \"/mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000001532\" --save_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:37:13 [DEBUG]: Loaded backend agg version v2.2.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 163, in <module>\n",
      "    mode, input_source = check_input()\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 137, in check_input\n",
      "    im_names = natsort.natsorted(im_names)\n",
      "UnboundLocalError: local variable 'im_names' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /mnt/d/Justine/uni/data/coco/val2017/000000001584.jpg\n",
      "Created directory: /mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000001584\n",
      "python /mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py --cfg /mnt/d/Justine/uni/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml --checkpoint /mnt/d/Justine/uni/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth --indir /mnt/d/Justine/uni/data/coco/val2017/000000001584.jpg --outdir \"/mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000001584\" --save_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:37:15 [DEBUG]: Loaded backend agg version v2.2.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 163, in <module>\n",
      "    mode, input_source = check_input()\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 137, in check_input\n",
      "    im_names = natsort.natsorted(im_names)\n",
      "UnboundLocalError: local variable 'im_names' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /mnt/d/Justine/uni/data/coco/val2017/000000001675.jpg\n",
      "Created directory: /mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000001675\n",
      "python /mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py --cfg /mnt/d/Justine/uni/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml --checkpoint /mnt/d/Justine/uni/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth --indir /mnt/d/Justine/uni/data/coco/val2017/000000001675.jpg --outdir \"/mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000001675\" --save_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:37:18 [DEBUG]: Loaded backend agg version v2.2.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 163, in <module>\n",
      "    mode, input_source = check_input()\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 137, in check_input\n",
      "    im_names = natsort.natsorted(im_names)\n",
      "UnboundLocalError: local variable 'im_names' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /mnt/d/Justine/uni/data/coco/val2017/000000001761.jpg\n",
      "Created directory: /mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000001761\n",
      "python /mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py --cfg /mnt/d/Justine/uni/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml --checkpoint /mnt/d/Justine/uni/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth --indir /mnt/d/Justine/uni/data/coco/val2017/000000001761.jpg --outdir \"/mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000001761\" --save_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:37:20 [DEBUG]: Loaded backend agg version v2.2.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 163, in <module>\n",
      "    mode, input_source = check_input()\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 137, in check_input\n",
      "    im_names = natsort.natsorted(im_names)\n",
      "UnboundLocalError: local variable 'im_names' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /mnt/d/Justine/uni/data/coco/val2017/000000001818.jpg\n",
      "Created directory: /mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000001818\n",
      "python /mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py --cfg /mnt/d/Justine/uni/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml --checkpoint /mnt/d/Justine/uni/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth --indir /mnt/d/Justine/uni/data/coco/val2017/000000001818.jpg --outdir \"/mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000001818\" --save_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:37:22 [DEBUG]: Loaded backend agg version v2.2.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 163, in <module>\n",
      "    mode, input_source = check_input()\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 137, in check_input\n",
      "    im_names = natsort.natsorted(im_names)\n",
      "UnboundLocalError: local variable 'im_names' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /mnt/d/Justine/uni/data/coco/val2017/000000001993.jpg\n",
      "Created directory: /mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000001993\n",
      "python /mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py --cfg /mnt/d/Justine/uni/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml --checkpoint /mnt/d/Justine/uni/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth --indir /mnt/d/Justine/uni/data/coco/val2017/000000001993.jpg --outdir \"/mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000001993\" --save_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:37:25 [DEBUG]: Loaded backend agg version v2.2.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 163, in <module>\n",
      "    mode, input_source = check_input()\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 137, in check_input\n",
      "    im_names = natsort.natsorted(im_names)\n",
      "UnboundLocalError: local variable 'im_names' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /mnt/d/Justine/uni/data/coco/val2017/000000002006.jpg\n",
      "Created directory: /mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000002006\n",
      "python /mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py --cfg /mnt/d/Justine/uni/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml --checkpoint /mnt/d/Justine/uni/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth --indir /mnt/d/Justine/uni/data/coco/val2017/000000002006.jpg --outdir \"/mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000002006\" --save_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:37:27 [DEBUG]: Loaded backend agg version v2.2.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 163, in <module>\n",
      "    mode, input_source = check_input()\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 137, in check_input\n",
      "    im_names = natsort.natsorted(im_names)\n",
      "UnboundLocalError: local variable 'im_names' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /mnt/d/Justine/uni/data/coco/val2017/000000002149.jpg\n",
      "Created directory: /mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000002149\n",
      "python /mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py --cfg /mnt/d/Justine/uni/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml --checkpoint /mnt/d/Justine/uni/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth --indir /mnt/d/Justine/uni/data/coco/val2017/000000002149.jpg --outdir \"/mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000002149\" --save_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:37:29 [DEBUG]: Loaded backend agg version v2.2.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 163, in <module>\n",
      "    mode, input_source = check_input()\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 137, in check_input\n",
      "    im_names = natsort.natsorted(im_names)\n",
      "UnboundLocalError: local variable 'im_names' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /mnt/d/Justine/uni/data/coco/val2017/000000002153.jpg\n",
      "Created directory: /mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000002153\n",
      "python /mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py --cfg /mnt/d/Justine/uni/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml --checkpoint /mnt/d/Justine/uni/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth --indir /mnt/d/Justine/uni/data/coco/val2017/000000002153.jpg --outdir \"/mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000002153\" --save_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:37:31 [DEBUG]: Loaded backend agg version v2.2.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 163, in <module>\n",
      "    mode, input_source = check_input()\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 137, in check_input\n",
      "    im_names = natsort.natsorted(im_names)\n",
      "UnboundLocalError: local variable 'im_names' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /mnt/d/Justine/uni/data/coco/val2017/000000002157.jpg\n",
      "Created directory: /mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000002157\n",
      "python /mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py --cfg /mnt/d/Justine/uni/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml --checkpoint /mnt/d/Justine/uni/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth --indir /mnt/d/Justine/uni/data/coco/val2017/000000002157.jpg --outdir \"/mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000002157\" --save_img\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:37:34 [DEBUG]: Loaded backend agg version v2.2.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 163, in <module>\n",
      "    mode, input_source = check_input()\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 137, in check_input\n",
      "    im_names = natsort.natsorted(im_names)\n",
      "UnboundLocalError: local variable 'im_names' referenced before assignment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /mnt/d/Justine/uni/data/coco/val2017/000000002261.jpg\n",
      "Created directory: /mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000002261\n",
      "python /mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py --cfg /mnt/d/Justine/uni/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml --checkpoint /mnt/d/Justine/uni/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth --indir /mnt/d/Justine/uni/data/coco/val2017/000000002261.jpg --outdir \"/mnt/d/Justine/uni/data/output/alphapose/coco/val2017_2/000000002261\" --save_img\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/d/Justine/uni/Pose Estimation/alphapose.ipynb Cell 3\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Justine/uni/Pose%20Estimation/alphapose.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m config \u001b[39m=\u001b[39m HOME_PATH \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Justine/uni/Pose%20Estimation/alphapose.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m checkpoint \u001b[39m=\u001b[39m HOME_PATH \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Justine/uni/Pose%20Estimation/alphapose.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m process_images(directory, directory_output, config, checkpoint)\n",
      "\u001b[1;32m/mnt/d/Justine/uni/Pose Estimation/alphapose.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Justine/uni/Pose%20Estimation/alphapose.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m \u001b[39mprint\u001b[39m(cmd)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Justine/uni/Pose%20Estimation/alphapose.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m p \u001b[39m=\u001b[39m subprocess\u001b[39m.\u001b[39mPopen(cmd, stdout\u001b[39m=\u001b[39msubprocess\u001b[39m.\u001b[39mPIPE, shell\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Justine/uni/Pose%20Estimation/alphapose.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=28'>29</a>\u001b[0m out, err \u001b[39m=\u001b[39m p\u001b[39m.\u001b[39;49mcommunicate()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.0/lib/python3.10/subprocess.py:1136\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1134\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stdin_write(\u001b[39minput\u001b[39m)\n\u001b[1;32m   1135\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout:\n\u001b[0;32m-> 1136\u001b[0m     stdout \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstdout\u001b[39m.\u001b[39;49mread()\n\u001b[1;32m   1137\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout\u001b[39m.\u001b[39mclose()\n\u001b[1;32m   1138\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-18 21:37:36 [DEBUG]: Loaded backend agg version v2.2.\n",
      "Traceback (most recent call last):\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 163, in <module>\n",
      "    mode, input_source = check_input()\n",
      "  File \"/mnt/d/Justine/uni/AlphaPose/scripts/demo_inference.py\", line 137, in check_input\n",
      "    im_names = natsort.natsorted(im_names)\n",
      "UnboundLocalError: local variable 'im_names' referenced before assignment\n"
     ]
    }
   ],
   "source": [
    "\n",
    "directory = HOME_PATH + \"/data/coco/val2017\"\n",
    "directory_output = HOME_PATH + \"/data/output/alphapose/coco/val2017_2\"\n",
    "config = HOME_PATH + '/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml'\n",
    "checkpoint = HOME_PATH + '/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth'\n",
    "\n",
    "process_images(directory, directory_output, config, checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5c8710",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "directory = HOME_PATH + \"/data/mpii/images\"\n",
    "directory_output = HOME_PATH + \"/data/output/alphapose/mpii\"\n",
    "config = HOME_PATH + '/AlphaPose/configs/halpe/256x192_res50_lr1e-3_1x.yaml'\n",
    "checkpoint = HOME_PATH + '/AlphaPose/pretrained_models/halpe26_fast_res50_256x192.pth'\n",
    "\n",
    "process_images(directory, directory_output, config, checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01232cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Script for single-gpu/multi-gpu demo.\"\"\"\n",
    "import argparse\n",
    "import os\n",
    "import platform\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import natsort\n",
    "\n",
    "from detector.apis import get_detector\n",
    "from trackers.tracker_api import Tracker\n",
    "from trackers.tracker_cfg import cfg as tcfg\n",
    "from trackers import track\n",
    "from alphapose.models import builder\n",
    "from alphapose.utils.config import update_config\n",
    "from alphapose.utils.detector import DetectionLoader\n",
    "from alphapose.utils.file_detector import FileDetectionLoader\n",
    "from alphapose.utils.transforms import flip, flip_heatmap\n",
    "from alphapose.utils.vis import getTime\n",
    "from alphapose.utils.webcam_detector import WebCamDetectionLoader\n",
    "from alphapose.utils.writer import DataWriter\n",
    "\n",
    "\"\"\"----------------------------- Demo options -----------------------------\"\"\"\n",
    "cfg=''#'experiment configure file name')\n",
    "checkpoint=''#'checkpoint file name')\n",
    "sp=False#'Use single process for pytorch')\n",
    "detector=''#'detector name=\"yolo\")\n",
    "detfile=''#'detection result file=\"\")\n",
    "inputpath=''#'image-directory=\"\")\n",
    "inputlist=''#'image-list=\"\")\n",
    "image=''#'image-name=\"\")\n",
    "outdir=''#'output-directory=\"examples/res/\")\n",
    "save_img=False#'save result as image')\n",
    "vis=False#'visualize image')\n",
    "showbox=False#'visualize human bbox')\n",
    "profile=False#'add speed profiling at screen output')\n",
    "format='coco'#'save in the format of cmu or coco or openpose, option: coco/cmu/open')\n",
    "min_box_area=0#'min box area to filter out')\n",
    "detbatch=5#'detection batch size PER GPU')\n",
    "posebatch=64#'pose estimation maximum batch size PER GPU')\n",
    "eval=False#'save the result json as coco format, using image index(int) instead of image name(str)')\n",
    "gpus=\"0\"#'choose which cuda device to use by index and input comma to use multi gpus, e.g. 0,1,2,3. (input -1 for cpu only)')\n",
    "qsize=1024#'the length of result buffer, where reducing it will lower requirement of cpu memory')\n",
    "flip=False#'enable flip testing')\n",
    "debug=False#'print detail information')\n",
    "\"\"\"----------------------------- Video options -----------------------------\"\"\"\n",
    "video=''#'video-name=\"\")\n",
    "webcam=-1#'webcam number=-1)\n",
    "save_video=''#'whether to save rendered video=False, action='store_true')\n",
    "vis_fast=''#'use fast rendering', action='store_true=False)\n",
    "\"\"\"----------------------------- Tracking options -----------------------------\"\"\"\n",
    "pose_flow=''#'track humans in video with PoseFlow', action='store_true=False)\n",
    "pose_track=''#'track humans in video with reid', action='store_true=False)\n",
    "\n",
    "args = parser.parse_args()\n",
    "cfg = update_config(args.cfg)\n",
    "\n",
    "if platform.system() == 'Windows':\n",
    "    args.sp = True\n",
    "\n",
    "args.gpus = [int(i) for i in args.gpus.split(',')] if torch.cuda.device_count() >= 1 else [-1]\n",
    "args.device = torch.device(\"cuda:\" + str(args.gpus[0]) if args.gpus[0] >= 0 else \"cpu\")\n",
    "args.detbatch = args.detbatch * len(args.gpus)\n",
    "args.posebatch = args.posebatch * len(args.gpus)\n",
    "args.tracking = args.pose_track or args.pose_flow or args.detector=='tracker'\n",
    "\n",
    "if not args.sp:\n",
    "    torch.multiprocessing.set_start_method('forkserver', force=True)\n",
    "    torch.multiprocessing.set_sharing_strategy('file_system')\n",
    "\n",
    "\n",
    "def check_input():\n",
    "    # for wecam\n",
    "    if args.webcam != -1:\n",
    "        args.detbatch = 1\n",
    "        return 'webcam', int(args.webcam)\n",
    "\n",
    "    # for video\n",
    "    if len(args.video):\n",
    "        if os.path.isfile(args.video):\n",
    "            videofile = args.video\n",
    "            return 'video', videofile\n",
    "        else:\n",
    "            raise IOError('Error: --video must refer to a video file, not directory.')\n",
    "\n",
    "    # for detection results\n",
    "    if len(args.detfile):\n",
    "        if os.path.isfile(args.detfile):\n",
    "            detfile = args.detfile\n",
    "            return 'detfile', detfile\n",
    "        else:\n",
    "            raise IOError('Error: --detfile must refer to a detection json file, not directory.')\n",
    "\n",
    "    # for images\n",
    "    if len(args.inputpath) or len(args.inputlist) or len(args.inputimg):\n",
    "        inputpath = args.inputpath\n",
    "        inputlist = args.inputlist\n",
    "        inputimg = args.inputimg\n",
    "\n",
    "        if len(inputlist):\n",
    "            im_names = open(inputlist, 'r').readlines()\n",
    "        elif len(inputpath) and inputpath != '/':\n",
    "            for root, dirs, files in os.walk(inputpath):\n",
    "                im_names = files\n",
    "            im_names = natsort.natsorted(im_names)\n",
    "        elif len(inputimg):\n",
    "            args.inputpath = os.path.split(inputimg)[0]\n",
    "            im_names = [os.path.split(inputimg)[1]]\n",
    "\n",
    "        return 'image', im_names\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "def print_finish_info():\n",
    "    print('===========================> Finish Model Running.')\n",
    "    if (args.save_img or args.save_video) and not args.vis_fast:\n",
    "        print('===========================> Rendering remaining images in the queue...')\n",
    "        print('===========================> If this step takes too long, you can enable the --vis_fast flag to use fast rendering (real-time).')\n",
    "\n",
    "\n",
    "def loop():\n",
    "    n = 0\n",
    "    while True:\n",
    "        yield n\n",
    "        n += 1\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mode, input_source = check_input()\n",
    "\n",
    "    if not os.path.exists(args.outputpath):\n",
    "        os.makedirs(args.outputpath)\n",
    "\n",
    "    # Load detection loader\n",
    "    if mode == 'webcam':\n",
    "        det_loader = WebCamDetectionLoader(input_source, get_detector(args), cfg, args)\n",
    "        det_worker = det_loader.start()\n",
    "    elif mode == 'detfile':\n",
    "        det_loader = FileDetectionLoader(input_source, cfg, args)\n",
    "        det_worker = det_loader.start()\n",
    "    else:\n",
    "        det_loader = DetectionLoader(input_source, get_detector(args), cfg, args, batchSize=args.detbatch, mode=mode, queueSize=args.qsize)\n",
    "        det_worker = det_loader.start()\n",
    "\n",
    "    # Load pose model\n",
    "    pose_model = builder.build_sppe(cfg.MODEL, preset_cfg=cfg.DATA_PRESET)\n",
    "\n",
    "    print('Loading pose model from %s...' % (args.checkpoint,))\n",
    "    pose_model.load_state_dict(torch.load(args.checkpoint, map_location=args.device))\n",
    "    pose_dataset = builder.retrieve_dataset(cfg.DATASET.TRAIN)\n",
    "    if args.pose_track:\n",
    "        tracker = Tracker(tcfg, args)\n",
    "    if len(args.gpus) > 1:\n",
    "        pose_model = torch.nn.DataParallel(pose_model, device_ids=args.gpus).to(args.device)\n",
    "    else:\n",
    "        pose_model.to(args.device)\n",
    "    pose_model.eval()\n",
    "\n",
    "    runtime_profile = {\n",
    "        'dt': [],\n",
    "        'pt': [],\n",
    "        'pn': []\n",
    "    }\n",
    "\n",
    "    # Init data writer\n",
    "    queueSize = 2 if mode == 'webcam' else args.qsize\n",
    "    if args.save_video and mode != 'image':\n",
    "        from alphapose.utils.writer import DEFAULT_VIDEO_SAVE_OPT as video_save_opt\n",
    "        if mode == 'video':\n",
    "            video_save_opt['savepath'] = os.path.join(args.outputpath, 'AlphaPose_' + os.path.basename(input_source))\n",
    "        else:\n",
    "            video_save_opt['savepath'] = os.path.join(args.outputpath, 'AlphaPose_webcam' + str(input_source) + '.mp4')\n",
    "        video_save_opt.update(det_loader.videoinfo)\n",
    "        writer = DataWriter(cfg, args, save_video=True, video_save_opt=video_save_opt, queueSize=queueSize).start()\n",
    "    else:\n",
    "        writer = DataWriter(cfg, args, save_video=False, queueSize=queueSize).start()\n",
    "\n",
    "    if mode == 'webcam':\n",
    "        print('Starting webcam demo, press Ctrl + C to terminate...')\n",
    "        sys.stdout.flush()\n",
    "        im_names_desc = tqdm(loop())\n",
    "    else:\n",
    "        data_len = det_loader.length\n",
    "        im_names_desc = tqdm(range(data_len), dynamic_ncols=True)\n",
    "\n",
    "    batchSize = args.posebatch\n",
    "    if args.flip:\n",
    "        batchSize = int(batchSize / 2)\n",
    "    try:\n",
    "        for i in im_names_desc:\n",
    "            start_time = getTime()\n",
    "            with torch.no_grad():\n",
    "                (inps, orig_img, im_name, boxes, scores, ids, cropped_boxes) = det_loader.read()\n",
    "                if orig_img is None:\n",
    "                    break\n",
    "                if boxes is None or boxes.nelement() == 0:\n",
    "                    writer.save(None, None, None, None, None, orig_img, im_name)\n",
    "                    continue\n",
    "                if args.profile:\n",
    "                    ckpt_time, det_time = getTime(start_time)\n",
    "                    runtime_profile['dt'].append(det_time)\n",
    "                # Pose Estimation\n",
    "                inps = inps.to(args.device)\n",
    "                datalen = inps.size(0)\n",
    "                leftover = 0\n",
    "                if (datalen) % batchSize:\n",
    "                    leftover = 1\n",
    "                num_batches = datalen // batchSize + leftover\n",
    "                hm = []\n",
    "                for j in range(num_batches):\n",
    "                    inps_j = inps[j * batchSize:min((j + 1) * batchSize, datalen)]\n",
    "                    if args.flip:\n",
    "                        inps_j = torch.cat((inps_j, flip(inps_j)))\n",
    "                    hm_j = pose_model(inps_j)\n",
    "                    if args.flip:\n",
    "                        hm_j_flip = flip_heatmap(hm_j[int(len(hm_j) / 2):], pose_dataset.joint_pairs, shift=True)\n",
    "                        hm_j = (hm_j[0:int(len(hm_j) / 2)] + hm_j_flip) / 2\n",
    "                    hm.append(hm_j)\n",
    "                hm = torch.cat(hm)\n",
    "                if args.profile:\n",
    "                    ckpt_time, pose_time = getTime(ckpt_time)\n",
    "                    runtime_profile['pt'].append(pose_time)\n",
    "                if args.pose_track:\n",
    "                    boxes,scores,ids,hm,cropped_boxes = track(tracker,args,orig_img,inps,boxes,hm,cropped_boxes,im_name,scores)\n",
    "                hm = hm.cpu()\n",
    "                writer.save(boxes, scores, ids, hm, cropped_boxes, orig_img, im_name)\n",
    "                if args.profile:\n",
    "                    ckpt_time, post_time = getTime(ckpt_time)\n",
    "                    runtime_profile['pn'].append(post_time)\n",
    "\n",
    "            if args.profile:\n",
    "                # TQDM\n",
    "                im_names_desc.set_description(\n",
    "                    'det time: {dt:.4f} | pose time: {pt:.4f} | post processing: {pn:.4f}'.format(\n",
    "                        dt=np.mean(runtime_profile['dt']), pt=np.mean(runtime_profile['pt']), pn=np.mean(runtime_profile['pn']))\n",
    "                )\n",
    "        print_finish_info()\n",
    "        while(writer.running()):\n",
    "            time.sleep(1)\n",
    "            print('===========================> Rendering remaining ' + str(writer.count()) + ' images in the queue...', end='\\r')\n",
    "        writer.stop()\n",
    "        det_loader.stop()\n",
    "    except Exception as e:\n",
    "        print(repr(e))\n",
    "        print('An error as above occurs when processing the images, please check it')\n",
    "        pass\n",
    "    except KeyboardInterrupt:\n",
    "        print_finish_info()\n",
    "        # Thread won't be killed when press Ctrl+C\n",
    "        if args.sp:\n",
    "            det_loader.terminate()\n",
    "            while(writer.running()):\n",
    "                time.sleep(1)\n",
    "                print('===========================> Rendering remaining ' + str(writer.count()) + ' images in the queue...', end='\\r')\n",
    "            writer.stop()\n",
    "        else:\n",
    "            # subprocesses are killed, manually clear queues\n",
    "\n",
    "            det_loader.terminate()\n",
    "            writer.terminate()\n",
    "            writer.clear_queues()\n",
    "            det_loader.clear_queues()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
