{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import customutils\n",
    "\n",
    "def getIDByName(labels, name):\n",
    "    return labels.index(name)\n",
    "\n",
    "def get_keypointconstants(classes_path):\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [float(c.strip()) for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "def getHeadSize(x1,y1,x2,y2):\n",
    "    headSize = 0.6*np.linalg.norm(np.subtract([x2,y2],[x1,y1]))\n",
    "    return headSize\n",
    "\n",
    "def getTopPoint(points):\n",
    "    point = []\n",
    "    for i in range(len(points)):\n",
    "        if (points[i][\"id\"] is not None and points[i][\"id\"] == \"Nose\"): # if joint id matches\n",
    "            point = points[i]\n",
    "            break\n",
    "\n",
    "    return point\n",
    "\n",
    "def getPointbyID(points,id):\n",
    "\n",
    "    point = []\n",
    "    for i in range(len(points)):\n",
    "        if (points[i][\"id\"] is not None and points[i][\"id\"] == id): # if joint id matches\n",
    "            point = points[i]\n",
    "            break\n",
    "\n",
    "    return point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYPOINT_CONSTANTS = get_keypointconstants('configs/keypointconstant.txt')\n",
    "LABELS_COCO = customutils.get_classes('configs/coco_classes.txt')\n",
    "\n",
    "\n",
    "def compute_scale(image_size, bounding_box):\n",
    "    # Get the width and height of the image\n",
    "    image_width, image_height = image_size\n",
    "\n",
    "    # Calculate the width and height of the bounding box\n",
    "    box_width = bounding_box[2][0] - bounding_box[0][0]\n",
    "    box_height = bounding_box[2][1] - bounding_box[0][1]\n",
    "\n",
    "    # Calculate the scale factors\n",
    "    scale_width = box_width / image_width\n",
    "    scale_height = box_height / image_height\n",
    "\n",
    "    # Choose the minimum scale factor\n",
    "    scale = min(scale_width, scale_height)\n",
    "\n",
    "    return scale\n",
    "\n",
    "def compute_oks(joint, d, area, visibility):\n",
    "    k = KEYPOINT_CONSTANTS[joint]\n",
    "    \n",
    "    # Compute the exponential part of the equation\n",
    "    exp_vector = np.exp(-(d**2) / (2 * (area) * (k**2)))\n",
    "    # The numerator expression\n",
    "    numerator = np.dot(exp_vector, visibility)\n",
    "    # The denominator expression\n",
    "    denominator = np.sum(visibility)\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from decimal import Decimal, ROUND_HALF_UP\n",
    "\n",
    "\n",
    "def edit_keypoints(kpts):\n",
    "    kpts = np.array(kpts).reshape(-1,3)\n",
    "    vi = kpts[:,2]\n",
    "    kpts = kpts[:,0:2]\n",
    "    return kpts, vi\n",
    "\n",
    "\n",
    "def OKS(kpts1, kpts2, sigma, area):\n",
    "\n",
    "    kpts1, vi1 = edit_keypoints(kpts1)\n",
    "    kpts2, vi2 = edit_keypoints(kpts2)\n",
    "\n",
    "    if np.shape(kpts1) != np.shape(kpts2):\n",
    "        print(kpts1, kpts2)\n",
    "        print(np.shape(kpts1), np.shape(kpts2))\n",
    "        raise ValueError(\"not same size\")\n",
    "    \n",
    "    k = 2*sigma\n",
    "    s = area\n",
    "\n",
    "    d = np.linalg.norm(kpts1 - kpts2, ord=2, axis=1)\n",
    "    v = np.ones(len(d))\n",
    "\n",
    "    for part in range(len(d)):\n",
    "        if vi1[part] == 0 or vi2[part] == 0:\n",
    "            d[part] = 0\n",
    "            v[part] = 0\n",
    "    \n",
    "    if np.sum(v)!=0:\n",
    "        OKS = (np.sum([(np.exp((-d[i]**2)/(2*s*(k[i]**2))))*v[i] for i in range(len(d))])/np.sum(v))\n",
    "    else:\n",
    "        OKS = 0\n",
    "    \n",
    "    OKS = float(Decimal(str(OKS)).quantize(Decimal('0.000001'), rounding=ROUND_HALF_UP))\n",
    "\n",
    "    return OKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeDistOks(gtLabels, gtFrames, prFrames):\n",
    "    # assert len(gtFrames) == len(prFrames)\n",
    "\n",
    "    nJoints = len(gtLabels)\n",
    "    distAll = {}\n",
    "    dist = {}\n",
    "    ious = {}\n",
    "    iousAll = {}\n",
    "    oksAll = defaultdict(list)\n",
    "    for joint in range(nJoints):\n",
    "        distAll[joint] = np.zeros([0,0])\n",
    "        iousAll[joint] = []\n",
    "\n",
    "    # for imgidx in range(len(gtFrames)):\n",
    "    for imgidx, gtFrame in gtFrames.items():\n",
    "        oksAll[imgidx] = []\n",
    "        # ground truth\n",
    "        # gtFrame = gtFrames[imgidx]\n",
    "        # prediction\n",
    "        detFrame = prFrames[imgidx]\n",
    "        prFramesLen = len(detFrame)\n",
    "        dist = np.ones((len(gtFrame), max(prFramesLen,1), nJoints)) * np.inf\n",
    "        ious = np.zeros((len(gtFrame), max(prFramesLen,1), nJoints))\n",
    "        oks_all = np.zeros((len(gtFrame), max(prFramesLen,1)))\n",
    "        \n",
    "        for personGT in range(len(gtFrame)):\n",
    "            rectGT = gtFrames[imgidx][personGT]\n",
    "            # if no poses predicted, initialise\n",
    "            if prFramesLen == 0:\n",
    "                for pidx in range(nJoints):\n",
    "                    dist[personGT, 0, pidx] = np.inf\n",
    "            else:\n",
    "                # compute distance between each detection and ground truth object\n",
    "                for personDT in range(prFramesLen):\n",
    "                    rectPr = prFrames[imgidx][personDT]\n",
    "                    if (\"person\" in rectGT.keys() and rectGT[\"person\"] is not None):\n",
    "                        pointsGT = rectGT[\"person\"][\"points\"]\n",
    "                        pointsPr = rectPr[\"person\"][\"points\"]\n",
    "                        bb = customutils.get_bb(pointsGT)\n",
    "                        area = customutils.compute_area(bb)\n",
    "\n",
    "                        for pidx, idxGT in enumerate(gtLabels):\n",
    "                            keypointGT = getPointbyID(pointsGT,idxGT)\n",
    "                            pointGT = [keypointGT[\"x\"],keypointGT[\"y\"]]\n",
    "                            idxGT = keypointGT[\"id\"]\n",
    "                            #idx = getIDByName(gtLabels, idxGT)\n",
    "                            p = getPointbyID(pointsPr,idxGT)\n",
    "                            if (len(p) > 0 and\n",
    "                                isinstance(p[\"x\"], (int, float)) and\n",
    "                                isinstance(p[\"y\"], (int, float)) and \n",
    "                                p[\"x\"] > 0 and\n",
    "                                p[\"y\"] > 0):\n",
    "                                pointPr = [p[\"x\"],p[\"y\"]]\n",
    "                                visible = 1\n",
    "                                if \"occluded\" in keypointGT.keys() and keypointGT[\"occluded\"] is not None:\n",
    "                                    if keypointGT[\"occluded\"] == \"False\":\n",
    "                                        visible = 2\n",
    "                                else:\n",
    "                                    visible = keypointGT[\"visibility\"]\n",
    "                                # compute distance between GT and prediction\n",
    "                                d = np.linalg.norm(np.subtract(pointGT,pointPr))\n",
    "                                oks = compute_oks(pidx, d, area, visible)\n",
    "                                # compute head size for distance normalization\n",
    "                                head = getPointbyID(pointsGT,\"Head\")\n",
    "                                neck = getPointbyID(pointsGT,\"Neck\")\n",
    "                                headSize = 1\n",
    "                                if (len(head) > 0 and len(neck) > 0):\n",
    "                                    headSize = getHeadSize(head[\"x\"], head[\"y\"], neck[\"x\"], neck[\"y\"])\n",
    "                                # normalize distance\n",
    "                                dNorm = d/headSize\n",
    "                            else:\n",
    "                                dNorm = np.inf\n",
    "                                oks = 0\n",
    "\n",
    "                            dist[personGT, personDT, pidx] = dNorm\n",
    "                            ious[personGT, personDT, pidx] = oks\n",
    "                            \n",
    "                        oks_all[personGT, personDT] = OKS(rectGT[\"person\"][\"kpts\"], rectPr[\"person\"][\"kpts\"], KEYPOINT_CONSTANTS, area)\n",
    "\n",
    "\n",
    "        #find matching detection (minimum distance) for each ground truth\n",
    "        for personGT in range(len(gtFrames[imgidx])):\n",
    "            min_dist = np.inf\n",
    "            if prFramesLen == 0:\n",
    "                minPersonDT = 0\n",
    "            for personDT in range(len(prFrames[imgidx])):\n",
    "                total_dist = 0\n",
    "                for idx in range(nJoints):\n",
    "                    if dist[personGT, personDT, idx] != np.inf:\n",
    "                        total_dist += dist[personGT, personDT, idx]\n",
    "                if total_dist < min_dist:\n",
    "                    min_dist = total_dist\n",
    "                    minPersonDT = personDT\n",
    "        \n",
    "            for idx in range(nJoints):\n",
    "                #print(str(dist[personGT, minPersonDT, idx]) + ' ' + str(personGT) + ' ' + str(minPersonDT) + ' ' + str(idx))\n",
    "                distAll[idx] = np.append(distAll[idx],[[dist[personGT, minPersonDT, idx]]])\n",
    "                iousAll[idx].append(ious[personGT, minPersonDT, idx])\n",
    "\n",
    "            oksAll[imgidx].append(oks_all[personGT, minPersonDT])\n",
    "\n",
    "\n",
    "    return distAll, iousAll, oksAll\n",
    "\n",
    "def computeAP(labels, iousAll, thresh):\n",
    "\n",
    "    ap = np.zeros([len(iousAll)+2,1])\n",
    "    nCorrect = 0\n",
    "    nTotal = 0\n",
    "    nCorrectCoco = 0\n",
    "    nTotalCoco = 0\n",
    "    for pidx in range(len(iousAll)):\n",
    "        if len(iousAll[pidx]) == 0:\n",
    "            print (pidx)\n",
    "            ap[pidx,0] = np.inf\n",
    "        else:\n",
    "            threshArr = np.ones(len(iousAll[pidx]))*thresh\n",
    "            idxs = np.argwhere(iousAll[pidx] >= threshArr)\n",
    "            oks = 100.0*len(idxs)/len(iousAll[pidx])\n",
    "            ap[pidx,0] = oks\n",
    "            nCorrect += len(idxs)\n",
    "            nTotal   += len(iousAll[pidx])\n",
    "            if labels[pidx] in LABELS_COCO:\n",
    "                nCorrectCoco += len(idxs)\n",
    "                nTotalCoco   += len(iousAll[pidx])\n",
    "    ap[len(iousAll),0] = 100.0*nCorrect/nTotal\n",
    "    ap[len(iousAll)+1,0] = 100.0*nCorrectCoco/nTotalCoco\n",
    "\n",
    "    return ap\n",
    "\n",
    "def computeAP_OKS(labels, iousAll, thresh):\n",
    "\n",
    "    ap = np.zeros([len(iousAll)+2,1])\n",
    "    nCorrect = 0\n",
    "    nTotal = 0\n",
    "    idx = 0\n",
    "    for pidx, val in iousAll.items():\n",
    "        threshArr = np.ones(len(iousAll[pidx]))*thresh\n",
    "        idxs = np.argwhere(iousAll[pidx] >= threshArr)\n",
    "        oks = 100.0*len(idxs)/len(iousAll[pidx])\n",
    "        ap[idx,0] = oks\n",
    "        nCorrect += len(idxs)\n",
    "        nTotal   += len(iousAll[pidx])\n",
    "        idx += 1\n",
    "    ap[len(iousAll),0] = 100.0*nCorrect/nTotal\n",
    "\n",
    "    return ap\n",
    "\n",
    "def computePCK(labels, distAll, distThresh):\n",
    "\n",
    "    pckAll = np.zeros([len(distAll)+2,1])\n",
    "    nCorrect = 0\n",
    "    nTotal = 0\n",
    "    nCorrectCoco = 0\n",
    "    nTotalCoco = 0\n",
    "    for pidx in range(len(distAll)):\n",
    "        idxs = np.argwhere(distAll[pidx] <= distThresh)\n",
    "        pck = 100.0*len(idxs)/len(distAll[pidx])\n",
    "        pckAll[pidx,0] = pck\n",
    "        nCorrect += len(idxs)\n",
    "        nTotal   += len(distAll[pidx])\n",
    "        if labels[pidx] in LABELS_COCO:\n",
    "            nCorrectCoco += len(idxs)\n",
    "            nTotalCoco   += len(distAll[pidx])\n",
    "    pckAll[len(distAll),0] = 100.0*nCorrect/nTotal\n",
    "    pckAll[len(distAll)+1,0] = 100.0*nCorrectCoco/nTotalCoco\n",
    "\n",
    "    return pckAll\n",
    "\n",
    "\n",
    "def computeMetrics(gtLabels, names, gtFramesAll, prFramesAll, file):\n",
    "\n",
    "    distThresh = 0.5\n",
    "\n",
    "    # compute distances\n",
    "    distAll, oks, oksAll = computeDistOks(gtLabels, gtFramesAll, prFramesAll)\n",
    "\n",
    "    ap50 = computeAP(gtLabels, oks, distThresh)\n",
    "    ap = np.copy(ap50)\n",
    "    for i in range(9):\n",
    "        distThresh += 0.05\n",
    "        ap += computeAP(gtLabels, oks, distThresh)\n",
    "    ap75 = computeAP(gtLabels, oks, 0.75)\n",
    "    ap = ap/10\n",
    "\n",
    "    ap50_2 = computeAP_OKS(gtLabels, oksAll, distThresh)\n",
    "    ap_2 = np.copy(ap50_2)\n",
    "    for i in range(9):\n",
    "        distThresh += 0.05\n",
    "        ap_2 += computeAP_OKS(gtLabels, oksAll, distThresh)\n",
    "    ap75_2 = computeAP_OKS(gtLabels, oksAll, 0.75)\n",
    "    ap_2 = ap_2/10\n",
    "\n",
    "    # compute PCK metric\n",
    "    pckAll = computePCK(gtLabels, distAll, distThresh)\n",
    "    metrics = {'pckh': pckAll.flatten().tolist(), \n",
    "               'AP': ap.flatten().tolist(),  \n",
    "               'AP0.5': ap50.flatten().tolist(),  \n",
    "               'AP0.75': ap75.flatten().tolist(),  \n",
    "               'AP_2': ap_2.flatten().tolist(),  \n",
    "               'AP0.5_2': ap50_2.flatten().tolist(),  \n",
    "               'AP0.75_2': ap75_2.flatten().tolist(),  \n",
    "               'names': names}\n",
    "    filename = 'results/results_pckh_' + file + '.json'\n",
    "    print('saving results to', filename)\n",
    "    customutils.writeJson(metrics,filename)\n",
    "\n",
    "    return pckAll, ap, ap50, ap75, ap_2, ap50_2, ap75_2\n",
    "\n",
    "\n",
    "#load_data(\"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, argparse, json, re\n",
    "\n",
    "def to60fps(i):\n",
    "    return i*2\n",
    "\n",
    "def load_prediction_files(gtLabels, labels, file_path, frame_count, is60fps):\n",
    "    frames = defaultdict(list)\n",
    "    common_labels = set()\n",
    "\n",
    "    for filename in os.listdir(file_path):\n",
    "        if filename.endswith('.json'):\n",
    "            full_file = os.path.join(file_path, filename)\n",
    "            with open(full_file, 'r') as f:            \n",
    "                pattern = '([0-9]*)([_a-z]*)\\.json$'\n",
    "                result = re.search(pattern, filename)\n",
    "                frame_index = int(result.groups(0)[0])\n",
    "                if frame_index < frame_count:# and (is60fps == 0 or frame_index % 2 == 0):\n",
    "                    predictions_annotations = json.load(f)\n",
    "                    person_id = 0\n",
    "                    for pose in predictions_annotations[\"people\"]:\n",
    "                        keypoints = frames[frame_index]\n",
    "                        pose_kpts = pose[\"pose_keypoints_2d\"]\n",
    "                        keypoints_index = 0\n",
    "                        points = []\n",
    "                        confidences = []\n",
    "                        kpts = []\n",
    "                        for label in labels:\n",
    "                            if label in gtLabels:\n",
    "                                common_labels.add(label)\n",
    "                                if keypoints_index < len(pose_kpts):\n",
    "                                    points.append({'id': label, 'x': pose_kpts[keypoints_index], 'y': pose_kpts[keypoints_index+1], 'confidence': pose_kpts[keypoints_index+2]})\n",
    "                                    kpts.append(pose_kpts[keypoints_index])\n",
    "                                    kpts.append(pose_kpts[keypoints_index+1])\n",
    "                                    kpts.append(2) #visibility\n",
    "                                    confidences.append(pose_kpts[keypoints_index+2])\n",
    "                            keypoints_index = keypoints_index + 3\n",
    "\n",
    "                        keypoint = {'points': points, 'confidence': confidences, 'kpts' : kpts}\n",
    "\n",
    "                        keypoints.append({'person': keypoint, 'person_id': person_id})\n",
    "                        person_id += 1\n",
    "\n",
    "                        frames[frame_index] = keypoints\n",
    "\n",
    "\n",
    "    return frames, common_labels\n",
    "\n",
    "\n",
    "def load_alphaposeframe(pose, frames, frame_count, prev_frameindex, person_id, labels, gtLabels, keypoints, is60fps):\n",
    "    if (\"image_id\" in pose and pose[\"image_id\"] is not None):\n",
    "            frame_id = pose[\"image_id\"]\n",
    "    else:\n",
    "        frame_id = pose\n",
    "    frame_index = int(frame_id.replace(\".jpg\", \"\"))\n",
    "    if prev_frameindex == frame_index:\n",
    "        person_id += 1\n",
    "    else:\n",
    "        person_id = 0\n",
    "    if frame_index < frame_count:# and (is60fps == 0 or frame_index % 2 == 0):\n",
    "        keypoints = frames[frame_index]\n",
    "        pose_kpts = pose[\"keypoints\"]\n",
    "        keypoints_index = 0\n",
    "        points = []\n",
    "        confidences = []\n",
    "        kpts = []\n",
    "        for label in labels:\n",
    "            if keypoints_index < len(pose_kpts):\n",
    "                points.append({'id': label, 'x': pose_kpts[keypoints_index], 'y': pose_kpts[keypoints_index+1], 'confidence': pose_kpts[keypoints_index+2]})\n",
    "                confidences.append(pose_kpts[keypoints_index+2])\n",
    "                if label in gtLabels:\n",
    "                    kpts.append(pose_kpts[keypoints_index])\n",
    "                    kpts.append(pose_kpts[keypoints_index+1])\n",
    "                    kpts.append(2) #visibility\n",
    "                    \n",
    "                keypoints_index = keypoints_index + 3\n",
    "\n",
    "        keypoint = {'points': points, 'confidence': confidences, 'kpts' : kpts}\n",
    "\n",
    "        keypoints.append({'person': keypoint, 'person_id': person_id })\n",
    "\n",
    "        frames[frame_index] = keypoints\n",
    "    prev_frameindex = frame_index\n",
    "    return frames, prev_frameindex, person_id, keypoints\n",
    "\n",
    "def load_predictions(gtLabels, labels, file_path, frame_count, is60fps):\n",
    "  frames = defaultdict(list)\n",
    "  common_labels = set()\n",
    "\n",
    "  with open(file_path, 'r') as f:\n",
    "      predictions_annotations = json.load(f)\n",
    "\n",
    "  keypoints = []\n",
    "  if (\"instance_info\" in predictions_annotations and predictions_annotations[\"instance_info\"] is not None):\n",
    "     for frame in predictions_annotations[\"instance_info\"]:\n",
    "        frame_index = frame[\"frame_id\"]-1\n",
    "        if frame_index < frame_count:# and (is60fps == 0 or frame_index % 2 == 0):\n",
    "            person_id = 0\n",
    "            keypoints = frames[frame_index]\n",
    "            for pose in frame[\"instances\"]:\n",
    "                pose_kpts = pose[\"keypoints\"]\n",
    "                keypoints_index = 0\n",
    "                points = []\n",
    "                confidences = []\n",
    "                kpts = []\n",
    "                for i, idx in enumerate(labels):\n",
    "                    if idx in gtLabels:\n",
    "                        common_labels.add(idx)\n",
    "                    if i < len(pose_kpts):\n",
    "                        points.append({'id': idx, 'x': pose_kpts[i][0], 'y': pose_kpts[i][1], 'confidence': pose[\"keypoint_scores\"][i]})\n",
    "                        confidences.append(pose[\"keypoint_scores\"][i])\n",
    "                        kpts.append(pose_kpts[i][0])\n",
    "                        kpts.append(pose_kpts[i][1])\n",
    "                        kpts.append(2) #visibility\n",
    "\n",
    "                keypoint = {'points': points, 'confidence': confidences, 'kpts' : kpts}\n",
    "\n",
    "                keypoints.append({'person': keypoint, 'person_id': person_id})\n",
    "                person_id += 1\n",
    "\n",
    "            frames[frame_index] = keypoints\n",
    "  else:\n",
    "    prev_frameindex = -1\n",
    "    person_id = 0\n",
    "    for pose in predictions_annotations:\n",
    "        frames, prev_frameindex, person_id, keypoints = load_alphaposeframe(pose, frames, frame_count, prev_frameindex, person_id, labels, gtLabels, keypoints, is60fps)\n",
    "\n",
    "  return frames, common_labels\n",
    "\n",
    "\n",
    "def load_annotations(labels, gtLabels, file_path, is60fps):\n",
    "    frames = defaultdict(list)\n",
    "    isExist = os.path.exists(file_path)\n",
    "    keypoints = defaultdict(list)\n",
    "    if isExist:\n",
    "      annotations = []\n",
    "      with open(file_path, 'r') as f:\n",
    "          annotations = json.load(f)\n",
    "\n",
    "          framecount = annotations['item']['slots'][0]['frame_count']\n",
    "          for person in annotations['annotations']:\n",
    "            \n",
    "            for frame_index in range(0, framecount):\n",
    "              points = []\n",
    "              if frame_index < len(person['frames']):\n",
    "                frame = person['frames'][str(frame_index)]\n",
    "                for node in frame['skeleton']['nodes']:\n",
    "                  if node['name'] in gtLabels:\n",
    "                    points.append({'id': node['name'], 'occluded' : node['occluded'], 'x' : node['x'], 'y': node['y']})\n",
    "\n",
    "              if len(points) > 0:\n",
    "                # Create a dictionary to map 'id' to its position in the order array\n",
    "                id_to_index = {id_value: index for index, id_value in enumerate(labels)}\n",
    "\n",
    "                # Sort the data based on the custom sorting key\n",
    "                sorted_data = sorted(points, key=lambda x: id_to_index.get(x['id'], float('inf')))\n",
    "                kpts = []\n",
    "                for point in sorted_data:\n",
    "                    if point['id'] in labels: #check joint is available for this technique\n",
    "                        kpts.append(point['x'])\n",
    "                        kpts.append(point['y'])\n",
    "\n",
    "                        if point[\"occluded\"] == \"false\":\n",
    "                            kpts.append(2)\n",
    "                        else:                       \n",
    "                            kpts.append(1)\n",
    "\n",
    "                index = frame_index\n",
    "                # if is60fps:\n",
    "                #     index = to60fps(frame_index)\n",
    "                keypoints[index].append({'person': {'points': points, 'kpts' : kpts}})\n",
    "\n",
    "        #   for frame in range(0, len(keypoints)):\n",
    "        #     frames[frame] = keypoints[frame]\n",
    "\n",
    "    return keypoints\n",
    "\n",
    "def load_data(file):\n",
    "    with open(file, 'r') as f:\n",
    "      manifest = json.load(f)\n",
    "\n",
    "    gtLabels = customutils.get_classes('configs/halpe26_classes.txt')\n",
    "    \n",
    "    names = gtLabels[:]\n",
    "    names.append('Total')\n",
    "    \n",
    "    apAll_2 = np.zeros([len(names),1])\n",
    "    ap50All_2 = np.zeros([len(names),1])\n",
    "    ap75All_2 = np.zeros([len(names),1])\n",
    "\n",
    "    names.append('Total (COCO)')\n",
    "\n",
    "    apAll = np.zeros([len(names),1])\n",
    "    ap50All = np.zeros([len(names),1])\n",
    "    ap75All = np.zeros([len(names),1])\n",
    "    pckAll = np.zeros([len(names),1])\n",
    "\n",
    "    for i in manifest['index']:\n",
    "        print('Processing ' + i['file'])\n",
    "\n",
    "        labels = customutils.get_classes(manifest['labels'])\n",
    "        is60fps = i['is60fps']\n",
    "        gt = load_annotations(labels, gtLabels, i['annotations'], is60fps)\n",
    "        predictions = i['predictions']\n",
    "        if os.path.isfile(predictions):\n",
    "            pred, labels = load_predictions(gtLabels, labels, predictions, len(gt), is60fps)\n",
    "        else:\n",
    "            pred, labels = load_prediction_files(gtLabels, labels, predictions, len(gt), is60fps)\n",
    "\n",
    "        pck, ap, ap50, ap75, ap_2, ap50_2, ap75_2 = computeMetrics(gtLabels, names, gt, pred, manifest['model'] + '_' + i['name'])\n",
    "        pckAll = (pckAll + pck)\n",
    "        apAll = (apAll + ap)\n",
    "        ap50All = (ap50All + ap50)\n",
    "        ap75All = (ap75All + ap75)\n",
    "\n",
    "    pckAll = pckAll/len(manifest['index'])\n",
    "    apAll = apAll/len(manifest['index'])\n",
    "    ap50All = ap50All/len(manifest['index'])\n",
    "    ap75All = ap75All/len(manifest['index'])\n",
    "\n",
    "    metrics = {'pckh': pckAll.flatten().tolist(), \n",
    "               'AP': apAll.flatten().tolist(),  \n",
    "               'AP0.5': ap50All.flatten().tolist(),  \n",
    "               'AP0.75': ap75All.flatten().tolist(), \n",
    "               'names': names}\n",
    "    filename = 'results/results_' +  file #manifest['model'] + '.json'\n",
    "    print('saving results to', filename)\n",
    "    customutils.writeJson(metrics,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_keypoints(gtLabels, predLabels, gt, annotations):\n",
    "    keypoints_index = 0\n",
    "    points = []\n",
    "    confidences = []\n",
    "    pose_kpts = annotations['keypoints']\n",
    "    for label in gtLabels:\n",
    "      points.append({'id': label, 'x': pose_kpts[keypoints_index], 'y': pose_kpts[keypoints_index+1], 'visibility': pose_kpts[keypoints_index+2]})\n",
    "      keypoints_index = keypoints_index + 3\n",
    "\n",
    "    # Create a dictionary to map 'id' to its position in the order array\n",
    "    id_to_index = {id_value: index for index, id_value in enumerate(predLabels)}\n",
    "\n",
    "    # Sort the data based on the custom sorting key\n",
    "    sorted_data = sorted(points, key=lambda x: id_to_index.get(x['id'], float('inf')))\n",
    "    kpts = []\n",
    "    for point in sorted_data:\n",
    "      kpts.append(point['x'])\n",
    "      kpts.append(point['y'])\n",
    "      kpts.append(point['visibility'])\n",
    "\n",
    "    gt[annotations['image_id']].append({'person': {'points': sorted_data, 'kpts' : kpts}})\n",
    "\n",
    "    return gt\n",
    "\n",
    "\n",
    "def load_alphapose_predictions(gtLabels, labels, file_path, frame_count):\n",
    "  frames = defaultdict(list)\n",
    "  common_labels = set()\n",
    "\n",
    "  with open(file_path, 'r') as f:\n",
    "    pose = json.load(f)\n",
    "\n",
    "    prev_frameindex = -1\n",
    "    person_id = 0\n",
    "    keypoints = []\n",
    "    frames, prev_frameindex, person_id, keypoints = load_alphaposeframe(pose, frames, frame_count, prev_frameindex, person_id, labels, gtLabels, keypoints)\n",
    "\n",
    "  return frames, common_labels\n",
    "\n",
    "def load_mpii():\n",
    "    with open('../data/mpii/trainval.json', 'r') as f:\n",
    "      manifest = json.load(f)\n",
    "\n",
    "def load_coco(model):\n",
    "    with open('../data/coco/annotations/person_keypoints_val2017.json', 'r') as f:\n",
    "      manifest = json.load(f)\n",
    "\n",
    "    gtLabels = customutils.get_classes('configs/coco_classes.txt')\n",
    "    \n",
    "    names = gtLabels[:]\n",
    "    names.append('Total')\n",
    "    names.append('Total (COCO)')\n",
    "\n",
    "    apAll = np.zeros([len(names),1])\n",
    "    ap50All = np.zeros([len(names),1])\n",
    "    ap75All = np.zeros([len(names),1])\n",
    "    pckAll = np.zeros([len(names),1])\n",
    "\n",
    "    gt = defaultdict(list)\n",
    "    predictions = defaultdict(list)\n",
    "    image_count = 0\n",
    "    for i in manifest['annotations']:\n",
    "      image_name = str(i['image_id']).zfill(12)\n",
    "      image = image_name + '.jpg'\n",
    "      image_count += 1\n",
    "\n",
    "      if model == 'alphapose':\n",
    "        labels = customutils.get_classes('configs/halpe26_classes.txt')\n",
    "\n",
    "        gt = load_keypoints(gtLabels, labels, gt, i)\n",
    "        predictions_file = '../data/output/alphapose/coco/val2017/' + image_name + '/alphapose-results.json'\n",
    "        # pred = load_alphapose_predictions(gtLabels, labels, file_path, 1)\n",
    "        if os.path.isfile(predictions_file):\n",
    "          pred, labels = load_predictions(gtLabels, labels, predictions_file, np.inf)\n",
    "        else:\n",
    "          pred, labels = load_prediction_files(gtLabels, labels, predictions_file, np.inf)\n",
    "\n",
    "        for k,v in pred.items():\n",
    "           predictions[k] = v\n",
    "\n",
    "    pck, ap, ap50, ap75, ap_2, ap50_2, ap75_2 = computeMetrics(gtLabels, names, gt, predictions, model + '_' + image_name)\n",
    "    pckAll = (pckAll + pck)\n",
    "    apAll = (apAll + ap)\n",
    "    ap50All = (ap50All + ap50)\n",
    "    ap75All = (ap75All + ap75)\n",
    "\n",
    "    pckAll = pckAll/image_count\n",
    "    apAll = apAll/image_count\n",
    "    ap50All = ap50All/image_count\n",
    "    ap75All = ap75All/image_count\n",
    "        \n",
    "    metrics = {'pckh': pckAll.flatten().tolist(), \n",
    "               'AP': apAll.flatten().tolist(),  \n",
    "               'AP0.5': ap50All.flatten().tolist(),  \n",
    "               'AP0.75': ap75All.flatten().tolist(),  \n",
    "               'AP_2': ap_2.flatten().tolist(),  \n",
    "               'AP0.5_2': ap50_2.flatten().tolist(),  \n",
    "               'AP0.75_2': ap75_2.flatten().tolist(), \n",
    "               'names': names}\n",
    "    filename = 'results/results_coco_' +  model + '.json'\n",
    "    print('saving results to', filename)\n",
    "    customutils.writeJson(metrics,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_coco('alphapose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data(\"manifest_cotracker.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Athletics_Mixed_Tokyo_2020_20_1.avi\n",
      "saving results to results/results_pckh_vitpose_Athletics_Mixed_Tokyo_2020_20_1.json\n",
      "Processing Triathlon_Women_Tokyo_2020_29.avi\n",
      "saving results to results/results_pckh_vitpose_Triathlon_Women_Tokyo_2020_29.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_1.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_10000m_Oregon_2022_1.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_2.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_10000m_Oregon_2022_2.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_23.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_10000m_Oregon_2022_23.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_25.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_10000m_Oregon_2022_25.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_28.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_10000m_Oregon_2022_28.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_38.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_10000m_Oregon_2022_38.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_46.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_10000m_Oregon_2022_46.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_49.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_10000m_Oregon_2022_49.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_5.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_10000m_Oregon_2022_5.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_18.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_5000m_Oregon_2022_18.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_20.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_5000m_Oregon_2022_20.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_21.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_5000m_Oregon_2022_21.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_26.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_5000m_Oregon_2022_26.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_3.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_5000m_Oregon_2022_3.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_9.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_5000m_Oregon_2022_9.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_10.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Women_10000m_Oregon_2022_10.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_2.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Women_10000m_Oregon_2022_2.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_32.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Women_10000m_Oregon_2022_32.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_35.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Women_10000m_Oregon_2022_35.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_43.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Women_10000m_Oregon_2022_43.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_46.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Women_10000m_Oregon_2022_46.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_5.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Women_10000m_Oregon_2022_5.json\n",
      "Processing World_Athletics_Women_5000m_Oregon_2022_24.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Women_5000m_Oregon_2022_24.json\n",
      "Processing World_Athletics_Women_5000m_Oregon_2022_26.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Women_5000m_Oregon_2022_26.json\n",
      "Processing World_Athletics_Women_5000m_Oregon_2022_28.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Women_5000m_Oregon_2022_28.json\n",
      "Processing World_Athletics_Women_5000m_Oregon_2022_7.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Women_5000m_Oregon_2022_7.json\n",
      "Processing World_Athletics_Women_Marathon_Oregon_2022_2.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Women_Marathon_Oregon_2022_2.json\n",
      "Processing World_Athletics_Women_Marathon_Oregon_2022_8.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Women_Marathon_Oregon_2022_8.json\n",
      "saving results to results/results_manifest_vitpose.json\n",
      "Processing Athletics_Mixed_Tokyo_2020_20_1.avi\n",
      "saving results to results/results_pckh_openpose_Athletics_Mixed_Tokyo_2020_20_1.json\n",
      "Processing Triathlon_Women_Tokyo_2020_29.avi\n",
      "saving results to results/results_pckh_openpose_Triathlon_Women_Tokyo_2020_29.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_1.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Men_10000m_Oregon_2022_1.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_2.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Men_10000m_Oregon_2022_2.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_23.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Men_10000m_Oregon_2022_23.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_25.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Men_10000m_Oregon_2022_25.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_28.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Men_10000m_Oregon_2022_28.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_38.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Men_10000m_Oregon_2022_38.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_46.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Men_10000m_Oregon_2022_46.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_49.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Men_10000m_Oregon_2022_49.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_5.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Men_10000m_Oregon_2022_5.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_18.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Men_5000m_Oregon_2022_18.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_20.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Men_5000m_Oregon_2022_20.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_21.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Men_5000m_Oregon_2022_21.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_26.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Men_5000m_Oregon_2022_26.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_3.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Men_5000m_Oregon_2022_3.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_9.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Men_5000m_Oregon_2022_9.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_10.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Women_10000m_Oregon_2022_10.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_2.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Women_10000m_Oregon_2022_2.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_32.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Women_10000m_Oregon_2022_32.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_35.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Women_10000m_Oregon_2022_35.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_43.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Women_10000m_Oregon_2022_43.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_46.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Women_10000m_Oregon_2022_46.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_5.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Women_10000m_Oregon_2022_5.json\n",
      "Processing World_Athletics_Women_5000m_Oregon_2022_24.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Women_5000m_Oregon_2022_24.json\n",
      "Processing World_Athletics_Women_5000m_Oregon_2022_26.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Women_5000m_Oregon_2022_26.json\n",
      "Processing World_Athletics_Women_5000m_Oregon_2022_28.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Women_5000m_Oregon_2022_28.json\n",
      "Processing World_Athletics_Women_5000m_Oregon_2022_7.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Women_5000m_Oregon_2022_7.json\n",
      "Processing World_Athletics_Women_Marathon_Oregon_2022_2.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Women_Marathon_Oregon_2022_2.json\n",
      "Processing World_Athletics_Women_Marathon_Oregon_2022_8.mp4\n",
      "saving results to results/results_pckh_openpose_World_Athletics_Women_Marathon_Oregon_2022_8.json\n",
      "saving results to results/results_manifest_openpose.json\n",
      "Processing Athletics_Mixed_Tokyo_2020_20_1.avi\n",
      "saving results to results/results_pckh_alphapose_Athletics_Mixed_Tokyo_2020_20_1.json\n",
      "Processing Triathlon_Women_Tokyo_2020_29.avi\n",
      "saving results to results/results_pckh_alphapose_Triathlon_Women_Tokyo_2020_29.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_1.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_10000m_Oregon_2022_1.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_2.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_10000m_Oregon_2022_2.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_23.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_10000m_Oregon_2022_23.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_25.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_10000m_Oregon_2022_25.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_28.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_10000m_Oregon_2022_28.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_38.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_10000m_Oregon_2022_38.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_46.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_10000m_Oregon_2022_46.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_49.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_10000m_Oregon_2022_49.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_5.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_10000m_Oregon_2022_5.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_18.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_5000m_Oregon_2022_18.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_20.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_5000m_Oregon_2022_20.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_21.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_5000m_Oregon_2022_21.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_26.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_5000m_Oregon_2022_26.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_3.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_5000m_Oregon_2022_3.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_9.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_5000m_Oregon_2022_9.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_10.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Women_10000m_Oregon_2022_10.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_2.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Women_10000m_Oregon_2022_2.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_32.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Women_10000m_Oregon_2022_32.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_35.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Women_10000m_Oregon_2022_35.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_43.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Women_10000m_Oregon_2022_43.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_46.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Women_10000m_Oregon_2022_46.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_5.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Women_10000m_Oregon_2022_5.json\n",
      "Processing World_Athletics_Women_5000m_Oregon_2022_24.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Women_5000m_Oregon_2022_24.json\n",
      "Processing World_Athletics_Women_5000m_Oregon_2022_26.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Women_5000m_Oregon_2022_26.json\n",
      "Processing World_Athletics_Women_5000m_Oregon_2022_28.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Women_5000m_Oregon_2022_28.json\n",
      "Processing World_Athletics_Women_5000m_Oregon_2022_7.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Women_5000m_Oregon_2022_7.json\n",
      "Processing World_Athletics_Women_Marathon_Oregon_2022_2.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Women_Marathon_Oregon_2022_2.json\n",
      "Processing World_Athletics_Women_Marathon_Oregon_2022_8.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Women_Marathon_Oregon_2022_8.json\n",
      "saving results to results/results_manifest_alphapose.json\n"
     ]
    }
   ],
   "source": [
    "load_data(\"manifest_vitpose.json\")\n",
    "load_data(\"manifest_openpose.json\")\n",
    "load_data(\"manifest_alphapose.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing clip_tri_1.mp4\n",
      "saving results to results/results_pckh_openpose_clip_tri_1.json\n",
      "Processing clip_tri_3.mp4\n",
      "saving results to results/results_pckh_openpose_clip_tri_3.json\n",
      "Processing clip_marathon_1.mp4\n",
      "saving results to results/results_pckh_openpose_clip_marathon_1.json\n",
      "Processing clip_10k_2.mp4\n",
      "saving results to results/results_pckh_openpose_clip_10k_2.json\n",
      "Processing short.mp4\n",
      "saving results to results/results_pckh_openpose_short.json\n",
      "saving results to results/results_openpose.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "load_data(\"vitpose.json\")\n",
    "load_data(\"rtmpose_cocowb.json\")\n",
    "load_data(\"openpose.json\")\n",
    "load_data(\"alphapose_halpe.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_images_annotations(labels, file_path):\n",
    "    isExist = os.path.exists(file_path)\n",
    "    kpts = []\n",
    "    if isExist:\n",
    "      annotations = []\n",
    "      with open(file_path, 'r') as f:\n",
    "          annotations = json.load(f)\n",
    "\n",
    "          for person in annotations['annotations']:\n",
    "            points = person['skeleton']['nodes']\n",
    "            # Create a dictionary to map 'id' to its position in the order array\n",
    "            id_to_index = {id_value: index for index, id_value in enumerate(labels)}\n",
    "\n",
    "            # Sort the data based on the custom sorting key\n",
    "            sorted_data = sorted(points, key=lambda x: id_to_index.get(x['name'], float('inf')))\n",
    "            \n",
    "            for point in sorted_data:\n",
    "                if point['name'] in labels: #check joint is available for this technique\n",
    "                    kpts.append(point['x'])\n",
    "                    kpts.append(point['y'])\n",
    "\n",
    "                    if point[\"occluded\"] == False:\n",
    "                        kpts.append(2)\n",
    "                    else:                       \n",
    "                        kpts.append(1)\n",
    "\n",
    "    return kpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[365.3412,\n",
       " 79.2983,\n",
       " 2,\n",
       " 374.4502,\n",
       " 73.8108,\n",
       " 2,\n",
       " 361.8294,\n",
       " 75.9641,\n",
       " 2,\n",
       " 385.9921,\n",
       " 78.2122,\n",
       " 2,\n",
       " 346.042,\n",
       " 91.9508,\n",
       " 1,\n",
       " 401.455,\n",
       " 109.2247,\n",
       " 2,\n",
       " 360.2213,\n",
       " 120.7645,\n",
       " 2,\n",
       " 433.7274,\n",
       " 145.6223,\n",
       " 2,\n",
       " 337.9237,\n",
       " 164.0296,\n",
       " 2,\n",
       " 447.3294,\n",
       " 165.3812,\n",
       " 2,\n",
       " 307.6751,\n",
       " 179.025,\n",
       " 2,\n",
       " 430.7623,\n",
       " 208.9949,\n",
       " 2,\n",
       " 398.3848,\n",
       " 218.046,\n",
       " 2,\n",
       " 428.7794,\n",
       " 294.2152,\n",
       " 2,\n",
       " 371.9856,\n",
       " 271.7572,\n",
       " 2,\n",
       " 467.2197,\n",
       " 350.0835,\n",
       " 2,\n",
       " 403.4492,\n",
       " 333.0599,\n",
       " 2,\n",
       " 371.04,\n",
       " 49.4705,\n",
       " 2,\n",
       " 371.3041,\n",
       " 97.9179,\n",
       " 2,\n",
       " 412.0828,\n",
       " 207.4898,\n",
       " 2,\n",
       " 443.4085,\n",
       " 379.8619,\n",
       " 2,\n",
       " 375.3589,\n",
       " 359.3317,\n",
       " 2,\n",
       " 443.9042,\n",
       " 378.1352,\n",
       " 2,\n",
       " 373.8601,\n",
       " 361.0585,\n",
       " 2,\n",
       " 483.2874,\n",
       " 368.3486,\n",
       " 2,\n",
       " 411.8238,\n",
       " 347.3236,\n",
       " 2]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtLabels = customutils.get_classes('configs/halpe26_classes.txt')\n",
    "\n",
    "keypoints = []\n",
    "kpts1 = load_images_annotations(gtLabels, '../data/coco/annotations/coco-gt/000000000785.json')\n",
    "keypoints.append(kpts1)\n",
    "\n",
    "kpts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[368.6721,\n",
       " 80.8959,\n",
       " 2,\n",
       " 375.5445,\n",
       " 75.9857,\n",
       " 2,\n",
       " 361.2622,\n",
       " 76.71,\n",
       " 2,\n",
       " 388.1182,\n",
       " 76.9607,\n",
       " 2,\n",
       " 353.9189,\n",
       " 80.8332,\n",
       " 2,\n",
       " 414.7433,\n",
       " 107.8151,\n",
       " 2,\n",
       " 353.0496,\n",
       " 124.3498,\n",
       " 2,\n",
       " 456.3799,\n",
       " 155.2042,\n",
       " 2,\n",
       " 342.9293,\n",
       " 171.544,\n",
       " 2,\n",
       " 445.3035,\n",
       " 161.4027,\n",
       " 2,\n",
       " 308.223,\n",
       " 176.7675,\n",
       " 2,\n",
       " 435.1099,\n",
       " 210.0321,\n",
       " 2,\n",
       " 397.5518,\n",
       " 216.3284,\n",
       " 2,\n",
       " 419.2093,\n",
       " 293.7643,\n",
       " 2,\n",
       " 358.9458,\n",
       " 268.3841,\n",
       " 2,\n",
       " 472.5054,\n",
       " 353.9551,\n",
       " 2,\n",
       " 397.692,\n",
       " 332.0504,\n",
       " 2,\n",
       " 369.0988,\n",
       " 57.7655,\n",
       " 2,\n",
       " 370.2896,\n",
       " 97.4653,\n",
       " 2,\n",
       " 413.3748,\n",
       " 207.483,\n",
       " 2,\n",
       " 438.3355,\n",
       " 375.9781,\n",
       " 2,\n",
       " 369.94,\n",
       " 356.8105,\n",
       " 2,\n",
       " 448.1727,\n",
       " 380.8186,\n",
       " 2,\n",
       " 375.9274,\n",
       " 360.6274,\n",
       " 2,\n",
       " 495.9998,\n",
       " 379.0496,\n",
       " 2,\n",
       " 423.2654,\n",
       " 359.4433,\n",
       " 2]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "kpts2 = load_images_annotations(gtLabels, '../data/coco/annotations/coco-s/000000000785.json')\n",
    "keypoints.append(kpts2)\n",
    "kpts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[368.07,\n",
       " 78.8625,\n",
       " 2,\n",
       " 376.8153,\n",
       " 72.9762,\n",
       " 2,\n",
       " 360.4468,\n",
       " 76.4432,\n",
       " 2,\n",
       " 387.9667,\n",
       " 78.3536,\n",
       " 2,\n",
       " 355.6846,\n",
       " 81.3116,\n",
       " 1,\n",
       " 405.1969,\n",
       " 113.2558,\n",
       " 2,\n",
       " 357.8428,\n",
       " 125.8521,\n",
       " 2,\n",
       " 442.5724,\n",
       " 149.0478,\n",
       " 2,\n",
       " 344.0494,\n",
       " 161.4848,\n",
       " 2,\n",
       " 450.4211,\n",
       " 162.3177,\n",
       " 1,\n",
       " 312.6603,\n",
       " 175.4851,\n",
       " 2,\n",
       " 425.7171,\n",
       " 202.1875,\n",
       " 2,\n",
       " 405.2467,\n",
       " 209.4897,\n",
       " 2,\n",
       " 428.0612,\n",
       " 288.9894,\n",
       " 2,\n",
       " 364.6221,\n",
       " 272.0337,\n",
       " 2,\n",
       " 470.9175,\n",
       " 353.6962,\n",
       " 2,\n",
       " 406.318,\n",
       " 331.3645,\n",
       " 2,\n",
       " 371.8902,\n",
       " 46.6982,\n",
       " 2,\n",
       " 372.2566,\n",
       " 99.7024,\n",
       " 1,\n",
       " 407.7843,\n",
       " 203.7594,\n",
       " 2,\n",
       " 433.1447,\n",
       " 382.9647,\n",
       " 2,\n",
       " 369.977,\n",
       " 366.2978,\n",
       " 2,\n",
       " 443.6153,\n",
       " 382.7756,\n",
       " 2,\n",
       " 376.8903,\n",
       " 359.8701,\n",
       " 2,\n",
       " 483.3892,\n",
       " 376.5085,\n",
       " 2,\n",
       " 416.163,\n",
       " 345.9372,\n",
       " 2]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "kpts3 = load_images_annotations(gtLabels, '../data/coco/annotations/coco-mr/000000000785.json')\n",
    "keypoints.append(kpts3)\n",
    "kpts3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kpts1, vi1 = customutils.edit_keypoints(kpts1)\n",
    "kpts2, vi2 = customutils.edit_keypoints(kpts2)\n",
    "kpts3, vi3 = customutils.edit_keypoints(kpts3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[365.3412,  79.2983],\n",
       "       [374.4502,  73.8108],\n",
       "       [361.8294,  75.9641],\n",
       "       [385.9921,  78.2122],\n",
       "       [346.042 ,  91.9508],\n",
       "       [401.455 , 109.2247],\n",
       "       [360.2213, 120.7645],\n",
       "       [433.7274, 145.6223],\n",
       "       [337.9237, 164.0296],\n",
       "       [447.3294, 165.3812],\n",
       "       [307.6751, 179.025 ],\n",
       "       [430.7623, 208.9949],\n",
       "       [398.3848, 218.046 ],\n",
       "       [428.7794, 294.2152],\n",
       "       [371.9856, 271.7572],\n",
       "       [467.2197, 350.0835],\n",
       "       [403.4492, 333.0599],\n",
       "       [371.04  ,  49.4705],\n",
       "       [371.3041,  97.9179],\n",
       "       [412.0828, 207.4898],\n",
       "       [443.4085, 379.8619],\n",
       "       [375.3589, 359.3317],\n",
       "       [443.9042, 378.1352],\n",
       "       [373.8601, 361.0585],\n",
       "       [483.2874, 368.3486],\n",
       "       [411.8238, 347.3236]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpts1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[367.3611    ,  79.68556667],\n",
       "       [375.60333333,  74.25756667],\n",
       "       [361.17946667,  76.37243333],\n",
       "       [387.359     ,  77.84216667],\n",
       "       [353.9189    ,  80.8332    ],\n",
       "       [407.13173333, 110.09853333],\n",
       "       [357.0379    , 123.65546667],\n",
       "       [444.22656667, 149.9581    ],\n",
       "       [341.63413333, 165.68613333],\n",
       "       [446.31645   , 163.39195   ],\n",
       "       [309.51946667, 177.09253333],\n",
       "       [430.52976667, 207.0715    ],\n",
       "       [400.39443333, 214.62136667],\n",
       "       [425.34996667, 292.32296667],\n",
       "       [365.1845    , 270.725     ],\n",
       "       [470.2142    , 352.57826667],\n",
       "       [402.4864    , 332.15826667],\n",
       "       [370.67633333,  51.3114    ],\n",
       "       [370.79685   ,  97.6916    ],\n",
       "       [411.08063333, 206.24406667],\n",
       "       [438.29623333, 379.60156667],\n",
       "       [371.75863333, 360.81333333],\n",
       "       [445.23073333, 380.57646667],\n",
       "       [375.55926667, 360.51866667],\n",
       "       [487.5588    , 374.63556667],\n",
       "       [417.08406667, 350.90136667]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "kpts = []\n",
    "for part in range(len(kpts1)):\n",
    "    kpts_sum = 0\n",
    "    kpts_cnt = 0\n",
    "    if vi1[part] == 2:\n",
    "        kpts_sum += kpts1[part]\n",
    "        kpts_cnt += 1\n",
    "    if vi2[part] == 2:\n",
    "        kpts_sum += kpts2[part]\n",
    "        kpts_cnt += 1\n",
    "    if vi3[part] == 2:\n",
    "        kpts_sum += kpts3[part]\n",
    "        kpts_cnt += 1\n",
    "\n",
    "    kpts.append(list(kpts_sum/kpts_cnt))\n",
    "\n",
    "kpts = np.array(kpts)\n",
    "kpts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = customutils.compute_area_keypoints(kpts[:,0], kpts[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.92496481e-10, 4.64064167e-10, 1.87964404e-10, 3.35567027e-10,\n",
       "       0.00000000e+00, 1.76083142e-09, 1.06722582e-09, 2.94758083e-09,\n",
       "       1.46449939e-09, 5.30376860e-10, 7.76660553e-10, 1.50745785e-09,\n",
       "       1.47076475e-09, 1.44120664e-09, 1.62668371e-09, 8.24421805e-10,\n",
       "       1.06319344e-09, 1.40982428e-09, 1.31968036e-10, 8.63110715e-10,\n",
       "       1.47596864e-09, 1.38274299e-09, 8.20965594e-10, 3.94653249e-10,\n",
       "       2.18660744e-09, 2.23598619e-09])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma = 0\n",
    "\n",
    "d = np.linalg.norm(kpts - kpts1, ord=2, axis=1)\n",
    "v = np.ones(len(kpts))\n",
    "for part in range(len(d)):\n",
    "    if vi1[part] != 2:\n",
    "        d[part] = 0\n",
    "        v[part] = 0\n",
    "\n",
    "sigma += (d**2)/(s**2)\n",
    "\n",
    "d = np.linalg.norm(kpts - kpts2, ord=2, axis=1)\n",
    "v = np.ones(len(kpts))\n",
    "for part in range(len(d)):\n",
    "    if vi2[part] != 2:\n",
    "        d[part] = 0\n",
    "        v[part] = 0\n",
    "\n",
    "sigma += (d**2)/(s**2)\n",
    "\n",
    "d = np.linalg.norm(kpts - kpts3, ord=2, axis=1)\n",
    "v = np.ones(len(kpts))\n",
    "for part in range(len(d)):\n",
    "    if vi3[part] != 2:\n",
    "        d[part] = 0\n",
    "        v[part] = 0\n",
    "\n",
    "sigma += (d**2)/(s**2)\n",
    "\n",
    "sigma = sigma/3\n",
    "np.sqrt(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.78427234,  1.72913452,  0.34755727,  1.16334351,  0.        ,\n",
       "        7.94669837,  4.04828799, 13.23726091,  5.99933818,  2.23230447,\n",
       "        1.33658987,  5.45369358,  3.31579961,  6.30755332,  6.66342183,\n",
       "        2.67306331,  4.79561326,  6.64409649,  0.55544059,  2.60732746,\n",
       "        3.62367942,  4.39660118,  2.95191403,  0.38385556,  9.52544861,\n",
       "       10.54388481])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.89478063e-14, -4.73695157e-15],\n",
       "       [-3.78956126e-14, -4.73695157e-15],\n",
       "       [-1.89478063e-14,  0.00000000e+00],\n",
       "       [-1.89478063e-14,  4.73695157e-15],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  1.89478063e-14],\n",
       "       [-1.89478063e-14,  4.73695157e-15],\n",
       "       [ 3.78956126e-14,  9.47390314e-15],\n",
       "       [-3.78956126e-14,  9.47390314e-15],\n",
       "       [ 2.84217094e-14,  0.00000000e+00],\n",
       "       [ 1.89478063e-14,  0.00000000e+00],\n",
       "       [ 5.68434189e-14,  9.47390314e-15],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00, -3.78956126e-14],\n",
       "       [ 1.89478063e-14, -3.78956126e-14],\n",
       "       [ 5.68434189e-14,  3.78956126e-14],\n",
       "       [ 0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00, -2.36847579e-15],\n",
       "       [ 0.00000000e+00, -7.10542736e-15],\n",
       "       [-1.89478063e-14,  0.00000000e+00],\n",
       "       [-3.78956126e-14,  0.00000000e+00],\n",
       "       [ 3.78956126e-14,  0.00000000e+00],\n",
       "       [-1.89478063e-14, -1.89478063e-14],\n",
       "       [-1.89478063e-14,  0.00000000e+00],\n",
       "       [ 1.89478063e-14, -1.89478063e-14],\n",
       "       [-5.68434189e-14,  3.78956126e-14]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "kpts_d=[]\n",
    "for part in range(len(kpts)):\n",
    "    d = 0\n",
    "    kpts_cnt = 0\n",
    "    if vi1[part] == 2:\n",
    "        d += kpts[part] - kpts1[part]\n",
    "        kpts_cnt += 1\n",
    "    if vi2[part] == 2:\n",
    "        d += kpts[part] - kpts2[part]\n",
    "        kpts_cnt += 1\n",
    "    if vi3[part] == 2:\n",
    "        d += kpts[part] - kpts3[part]\n",
    "        kpts_cnt += 1\n",
    "\n",
    "    kpts_d.append(list(d/kpts_cnt))\n",
    "kpts_d = np.array(kpts_d)\n",
    "kpts_d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
