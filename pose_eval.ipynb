{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import customutils\n",
    "\n",
    "def getIDByName(labels, name):\n",
    "    return labels.index(name)\n",
    "\n",
    "def get_keypointconstants(classes_path):\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [float(c.strip()) for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "def getHeadSize(x1,y1,x2,y2):\n",
    "    headSize = 0.6*np.linalg.norm(np.subtract([x2,y2],[x1,y1]))\n",
    "    return headSize\n",
    "\n",
    "def getTopPoint(points):\n",
    "    point = []\n",
    "    for i in range(len(points)):\n",
    "        if (points[i][\"id\"] is not None and points[i][\"id\"] == \"Nose\"): # if joint id matches\n",
    "            point = points[i]\n",
    "            break\n",
    "\n",
    "    return point\n",
    "\n",
    "def getPointbyID(points,id):\n",
    "\n",
    "    point = []\n",
    "    for i in range(len(points)):\n",
    "        if (points[i][\"id\"] is not None and points[i][\"id\"] == id): # if joint id matches\n",
    "            point = points[i]\n",
    "            break\n",
    "\n",
    "    return point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYPOINT_CONSTANTS = get_keypointconstants('configs/keypointconstant.txt')\n",
    "LABELS_COCO = customutils.get_classes('configs/coco_classes.txt')\n",
    "\n",
    "\n",
    "def compute_scale(image_size, bounding_box):\n",
    "    # Get the width and height of the image\n",
    "    image_width, image_height = image_size\n",
    "\n",
    "    # Calculate the width and height of the bounding box\n",
    "    box_width = bounding_box[2][0] - bounding_box[0][0]\n",
    "    box_height = bounding_box[2][1] - bounding_box[0][1]\n",
    "\n",
    "    # Calculate the scale factors\n",
    "    scale_width = box_width / image_width\n",
    "    scale_height = box_height / image_height\n",
    "\n",
    "    # Choose the minimum scale factor\n",
    "    scale = min(scale_width, scale_height)\n",
    "\n",
    "    return scale\n",
    "\n",
    "def compute_oks(joint, d, area, visibility):\n",
    "    k = KEYPOINT_CONSTANTS[joint]\n",
    "    \n",
    "    # Compute the exponential part of the equation\n",
    "    exp_vector = np.exp(-(d**2) / (2 * (area) * (k**2)))\n",
    "    # The numerator expression\n",
    "    numerator = np.dot(exp_vector, visibility)\n",
    "    # The denominator expression\n",
    "    denominator = np.sum(visibility)\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from decimal import Decimal, ROUND_HALF_UP\n",
    "\n",
    "\n",
    "def edit_keypoints(kpts):\n",
    "    kpts = np.array(kpts).reshape(-1,3)\n",
    "    vi = kpts[:,2]\n",
    "    kpts = kpts[:,0:2]\n",
    "    return kpts, vi\n",
    "\n",
    "\n",
    "def OKS(kpts1, kpts2, sigma, area):\n",
    "\n",
    "    kpts1, vi1 = edit_keypoints(kpts1)\n",
    "    kpts2, vi2 = edit_keypoints(kpts2)\n",
    "\n",
    "    if np.shape(kpts1) != np.shape(kpts2):\n",
    "        print(kpts1, kpts2)\n",
    "        print(np.shape(kpts1), np.shape(kpts2))\n",
    "        raise ValueError(\"not same size\")\n",
    "    \n",
    "    k = 2*sigma\n",
    "    s = area\n",
    "\n",
    "    d = np.linalg.norm(kpts1 - kpts2, ord=2, axis=1)\n",
    "    v = np.ones(len(d))\n",
    "\n",
    "    for part in range(len(d)):\n",
    "        if vi1[part] == 0 or vi2[part] == 0:\n",
    "            d[part] = 0\n",
    "            v[part] = 0\n",
    "    \n",
    "    if np.sum(v)!=0:\n",
    "        OKS = (np.sum([(np.exp((-d[i]**2)/(2*s*(k[i]**2))))*v[i] for i in range(len(d))])/np.sum(v))\n",
    "    else:\n",
    "        OKS = 0\n",
    "    \n",
    "    OKS = float(Decimal(str(OKS)).quantize(Decimal('0.000001'), rounding=ROUND_HALF_UP))\n",
    "\n",
    "    return OKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeDistOks(gtLabels, gtFrames, prFrames):\n",
    "    # assert len(gtFrames) == len(prFrames)\n",
    "\n",
    "    nJoints = len(gtLabels)\n",
    "    distAll = {}\n",
    "    dist = {}\n",
    "    ious = {}\n",
    "    iousAll = {}\n",
    "    oksAll = defaultdict(list)\n",
    "    for joint in range(nJoints):\n",
    "        distAll[joint] = np.zeros([0,0])\n",
    "        iousAll[joint] = []\n",
    "\n",
    "    # for imgidx in range(len(gtFrames)):\n",
    "    for imgidx, gtFrame in gtFrames.items():\n",
    "        oksAll[imgidx] = []\n",
    "        # ground truth\n",
    "        # gtFrame = gtFrames[imgidx]\n",
    "        # prediction\n",
    "        detFrame = prFrames[imgidx]\n",
    "        prFramesLen = len(detFrame)\n",
    "        dist = np.ones((len(gtFrame), max(prFramesLen,1), nJoints)) * np.inf\n",
    "        ious = np.zeros((len(gtFrame), max(prFramesLen,1), nJoints))\n",
    "        oks_all = np.zeros((len(gtFrame), max(prFramesLen,1)))\n",
    "        \n",
    "        for personGT in range(len(gtFrame)):\n",
    "            rectGT = gtFrames[imgidx][personGT]\n",
    "            # if no poses predicted, initialise\n",
    "            if prFramesLen == 0:\n",
    "                for pidx in range(nJoints):\n",
    "                    dist[personGT, 0, pidx] = np.inf\n",
    "            else:\n",
    "                # compute distance between each detection and ground truth object\n",
    "                for personDT in range(prFramesLen):\n",
    "                    rectPr = prFrames[imgidx][personDT]\n",
    "                    if (\"person\" in rectGT.keys() and rectGT[\"person\"] is not None):\n",
    "                        pointsGT = rectGT[\"person\"][\"points\"]\n",
    "                        pointsPr = rectPr[\"person\"][\"points\"]\n",
    "                        bb = customutils.get_bb(pointsGT)\n",
    "                        area = customutils.compute_area(bb)\n",
    "\n",
    "                        for pidx, idxGT in enumerate(gtLabels):\n",
    "                            keypointGT = getPointbyID(pointsGT,idxGT)\n",
    "                            pointGT = [keypointGT[\"x\"],keypointGT[\"y\"]]\n",
    "                            idxGT = keypointGT[\"id\"]\n",
    "                            #idx = getIDByName(gtLabels, idxGT)\n",
    "                            p = getPointbyID(pointsPr,idxGT)\n",
    "                            if (len(p) > 0 and\n",
    "                                isinstance(p[\"x\"], (int, float)) and\n",
    "                                isinstance(p[\"y\"], (int, float)) and \n",
    "                                p[\"x\"] > 0 and\n",
    "                                p[\"y\"] > 0):\n",
    "                                pointPr = [p[\"x\"],p[\"y\"]]\n",
    "                                visible = 1\n",
    "                                if \"occluded\" in keypointGT.keys() and keypointGT[\"occluded\"] is not None:\n",
    "                                    if keypointGT[\"occluded\"] == \"False\":\n",
    "                                        visible = 2\n",
    "                                else:\n",
    "                                    visible = keypointGT[\"visibility\"]\n",
    "                                # compute distance between GT and prediction\n",
    "                                d = np.linalg.norm(np.subtract(pointGT,pointPr))\n",
    "                                oks = compute_oks(pidx, d, area, visible)\n",
    "                                # compute head size for distance normalization\n",
    "                                head = getPointbyID(pointsGT,\"Head\")\n",
    "                                neck = getPointbyID(pointsGT,\"Neck\")\n",
    "                                headSize = 1\n",
    "                                if (len(head) > 0 and len(neck) > 0):\n",
    "                                    headSize = getHeadSize(head[\"x\"], head[\"y\"], neck[\"x\"], neck[\"y\"])\n",
    "                                # normalize distance\n",
    "                                dNorm = d/headSize\n",
    "                            else:\n",
    "                                dNorm = np.inf\n",
    "                                oks = 0\n",
    "\n",
    "                            dist[personGT, personDT, pidx] = dNorm\n",
    "                            ious[personGT, personDT, pidx] = oks\n",
    "                            \n",
    "                        oks_all[personGT, personDT] = OKS(rectGT[\"person\"][\"kpts\"], rectPr[\"person\"][\"kpts\"], KEYPOINT_CONSTANTS, area)\n",
    "\n",
    "\n",
    "        #find matching detection (minimum distance) for each ground truth\n",
    "        for personGT in range(len(gtFrames[imgidx])):\n",
    "            min_dist = np.inf\n",
    "            if prFramesLen == 0:\n",
    "                minPersonDT = 0\n",
    "            for personDT in range(len(prFrames[imgidx])):\n",
    "                total_dist = 0\n",
    "                for idx in range(nJoints):\n",
    "                    if dist[personGT, personDT, idx] != np.inf:\n",
    "                        total_dist += dist[personGT, personDT, idx]\n",
    "                if total_dist < min_dist:\n",
    "                    min_dist = total_dist\n",
    "                    minPersonDT = personDT\n",
    "        \n",
    "            for idx in range(nJoints):\n",
    "                #print(str(dist[personGT, minPersonDT, idx]) + ' ' + str(personGT) + ' ' + str(minPersonDT) + ' ' + str(idx))\n",
    "                distAll[idx] = np.append(distAll[idx],[[dist[personGT, minPersonDT, idx]]])\n",
    "                iousAll[idx].append(ious[personGT, minPersonDT, idx])\n",
    "\n",
    "            oksAll[imgidx].append(oks_all[personGT, minPersonDT])\n",
    "\n",
    "\n",
    "    return distAll, iousAll, oksAll\n",
    "\n",
    "def computeAP(labels, iousAll, thresh):\n",
    "\n",
    "    ap = np.zeros([len(iousAll)+2,1])\n",
    "    nCorrect = 0\n",
    "    nTotal = 0\n",
    "    nCorrectCoco = 0\n",
    "    nTotalCoco = 0\n",
    "    for pidx in range(len(iousAll)):\n",
    "        if len(iousAll[pidx]) == 0:\n",
    "            print (pidx)\n",
    "            ap[pidx,0] = np.inf\n",
    "        else:\n",
    "            threshArr = np.ones(len(iousAll[pidx]))*thresh\n",
    "            idxs = np.argwhere(iousAll[pidx] >= threshArr)\n",
    "            oks = 100.0*len(idxs)/len(iousAll[pidx])\n",
    "            ap[pidx,0] = oks\n",
    "            nCorrect += len(idxs)\n",
    "            nTotal   += len(iousAll[pidx])\n",
    "            if labels[pidx] in LABELS_COCO:\n",
    "                nCorrectCoco += len(idxs)\n",
    "                nTotalCoco   += len(iousAll[pidx])\n",
    "    ap[len(iousAll),0] = 100.0*nCorrect/nTotal\n",
    "    ap[len(iousAll)+1,0] = 100.0*nCorrectCoco/nTotalCoco\n",
    "\n",
    "    return ap\n",
    "\n",
    "def computeAP_OKS(labels, iousAll, thresh):\n",
    "\n",
    "    ap = np.zeros([len(iousAll)+2,1])\n",
    "    nCorrect = 0\n",
    "    nTotal = 0\n",
    "    idx = 0\n",
    "    for pidx, val in iousAll.items():\n",
    "        threshArr = np.ones(len(iousAll[pidx]))*thresh\n",
    "        idxs = np.argwhere(iousAll[pidx] >= threshArr)\n",
    "        oks = 100.0*len(idxs)/len(iousAll[pidx])\n",
    "        ap[idx,0] = oks\n",
    "        nCorrect += len(idxs)\n",
    "        nTotal   += len(iousAll[pidx])\n",
    "        idx += 1\n",
    "    ap[len(iousAll),0] = 100.0*nCorrect/nTotal\n",
    "\n",
    "    return ap\n",
    "\n",
    "def computePCK(labels, distAll, distThresh):\n",
    "\n",
    "    pckAll = np.zeros([len(distAll)+2,1])\n",
    "    nCorrect = 0\n",
    "    nTotal = 0\n",
    "    nCorrectCoco = 0\n",
    "    nTotalCoco = 0\n",
    "    for pidx in range(len(distAll)):\n",
    "        idxs = np.argwhere(distAll[pidx] <= distThresh)\n",
    "        pck = 100.0*len(idxs)/len(distAll[pidx])\n",
    "        pckAll[pidx,0] = pck\n",
    "        nCorrect += len(idxs)\n",
    "        nTotal   += len(distAll[pidx])\n",
    "        if labels[pidx] in LABELS_COCO:\n",
    "            nCorrectCoco += len(idxs)\n",
    "            nTotalCoco   += len(distAll[pidx])\n",
    "    pckAll[len(distAll),0] = 100.0*nCorrect/nTotal\n",
    "    pckAll[len(distAll)+1,0] = 100.0*nCorrectCoco/nTotalCoco\n",
    "\n",
    "    return pckAll\n",
    "\n",
    "\n",
    "def computeMetrics(gtLabels, names, gtFramesAll, prFramesAll, file):\n",
    "\n",
    "    distThresh = 0.5\n",
    "\n",
    "    # compute distances\n",
    "    distAll, oks, oksAll = computeDistOks(gtLabels, gtFramesAll, prFramesAll)\n",
    "\n",
    "    ap50 = computeAP(gtLabels, oks, distThresh)\n",
    "    ap = np.copy(ap50)\n",
    "    for i in range(9):\n",
    "        distThresh += 0.05\n",
    "        ap += computeAP(gtLabels, oks, distThresh)\n",
    "    ap75 = computeAP(gtLabels, oks, 0.75)\n",
    "    ap = ap/10\n",
    "\n",
    "    ap50_2 = computeAP_OKS(gtLabels, oksAll, distThresh)\n",
    "    ap_2 = np.copy(ap50_2)\n",
    "    for i in range(9):\n",
    "        distThresh += 0.05\n",
    "        ap_2 += computeAP_OKS(gtLabels, oksAll, distThresh)\n",
    "    ap75_2 = computeAP_OKS(gtLabels, oksAll, 0.75)\n",
    "    ap_2 = ap_2/10\n",
    "\n",
    "    # compute PCK metric\n",
    "    pckAll = computePCK(gtLabels, distAll, distThresh)\n",
    "    metrics = {'pckh': pckAll.flatten().tolist(), \n",
    "               'AP': ap.flatten().tolist(),  \n",
    "               'AP0.5': ap50.flatten().tolist(),  \n",
    "               'AP0.75': ap75.flatten().tolist(),  \n",
    "               'AP_2': ap_2.flatten().tolist(),  \n",
    "               'AP0.5_2': ap50_2.flatten().tolist(),  \n",
    "               'AP0.75_2': ap75_2.flatten().tolist(),  \n",
    "               'names': names}\n",
    "    filename = 'results/results_pckh_' + file + '.json'\n",
    "    print('saving results to', filename)\n",
    "    customutils.writeJson(metrics,filename)\n",
    "\n",
    "    return pckAll, ap, ap50, ap75, ap_2, ap50_2, ap75_2\n",
    "\n",
    "\n",
    "#load_data(\"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, argparse, json, re\n",
    "\n",
    "def to60fps(i):\n",
    "    return i*2\n",
    "\n",
    "def load_prediction_files(gtLabels, labels, file_path, frame_count, is60fps):\n",
    "    frames = defaultdict(list)\n",
    "    common_labels = set()\n",
    "\n",
    "    for filename in os.listdir(file_path):\n",
    "        if filename.endswith('.json'):\n",
    "            full_file = os.path.join(file_path, filename)\n",
    "            with open(full_file, 'r') as f:            \n",
    "                pattern = '([0-9]*)([_a-z]*)\\.json$'\n",
    "                result = re.search(pattern, filename)\n",
    "                frame_index = int(result.groups(0)[0])\n",
    "                if frame_index < frame_count and (is60fps == 0 or frame_index % 2 == 0):\n",
    "                    predictions_annotations = json.load(f)\n",
    "                    person_id = 0\n",
    "                    for pose in predictions_annotations[\"people\"]:\n",
    "                        keypoints = frames[frame_index]\n",
    "                        pose_kpts = pose[\"pose_keypoints_2d\"]\n",
    "                        keypoints_index = 0\n",
    "                        points = []\n",
    "                        confidences = []\n",
    "                        kpts = []\n",
    "                        for label in labels:\n",
    "                            if label in gtLabels:\n",
    "                                common_labels.add(label)\n",
    "                                if keypoints_index < len(pose_kpts):\n",
    "                                    points.append({'id': label, 'x': pose_kpts[keypoints_index], 'y': pose_kpts[keypoints_index+1], 'confidence': pose_kpts[keypoints_index+2]})\n",
    "                                    kpts.append(pose_kpts[keypoints_index])\n",
    "                                    kpts.append(pose_kpts[keypoints_index+1])\n",
    "                                    kpts.append(2) #visibility\n",
    "                                    confidences.append(pose_kpts[keypoints_index+2])\n",
    "                            keypoints_index = keypoints_index + 3\n",
    "\n",
    "                        keypoint = {'points': points, 'confidence': confidences, 'kpts' : kpts}\n",
    "\n",
    "                        keypoints.append({'person': keypoint, 'person_id': person_id})\n",
    "                        person_id += 1\n",
    "\n",
    "                        frames[frame_index] = keypoints\n",
    "\n",
    "\n",
    "    return frames, common_labels\n",
    "\n",
    "\n",
    "def load_alphaposeframe(pose, frames, frame_count, prev_frameindex, person_id, labels, gtLabels, keypoints, is60fps):\n",
    "    if (\"image_id\" in pose and pose[\"image_id\"] is not None):\n",
    "            frame_id = pose[\"image_id\"]\n",
    "    else:\n",
    "        frame_id = pose\n",
    "    frame_index = int(frame_id.replace(\".jpg\", \"\"))\n",
    "    if prev_frameindex == frame_index:\n",
    "        person_id += 1\n",
    "    else:\n",
    "        person_id = 0\n",
    "    if frame_index < frame_count and (is60fps == 0 or frame_index % 2 == 0):\n",
    "        keypoints = frames[frame_index]\n",
    "        pose_kpts = pose[\"keypoints\"]\n",
    "        keypoints_index = 0\n",
    "        points = []\n",
    "        confidences = []\n",
    "        kpts = []\n",
    "        for label in labels:\n",
    "            if keypoints_index < len(pose_kpts):\n",
    "                points.append({'id': label, 'x': pose_kpts[keypoints_index], 'y': pose_kpts[keypoints_index+1], 'confidence': pose_kpts[keypoints_index+2]})\n",
    "                confidences.append(pose_kpts[keypoints_index+2])\n",
    "                if label in gtLabels:\n",
    "                    kpts.append(pose_kpts[keypoints_index])\n",
    "                    kpts.append(pose_kpts[keypoints_index+1])\n",
    "                    kpts.append(2) #visibility\n",
    "                    \n",
    "                keypoints_index = keypoints_index + 3\n",
    "\n",
    "        keypoint = {'points': points, 'confidence': confidences, 'kpts' : kpts}\n",
    "\n",
    "        keypoints.append({'person': keypoint, 'person_id': person_id })\n",
    "\n",
    "        frames[frame_index] = keypoints\n",
    "    prev_frameindex = frame_index\n",
    "    return frames, prev_frameindex, person_id, keypoints\n",
    "\n",
    "def load_predictions(gtLabels, labels, file_path, frame_count, is60fps):\n",
    "  frames = defaultdict(list)\n",
    "  common_labels = set()\n",
    "\n",
    "  with open(file_path, 'r') as f:\n",
    "      predictions_annotations = json.load(f)\n",
    "\n",
    "  keypoints = []\n",
    "  if (\"instance_info\" in predictions_annotations and predictions_annotations[\"instance_info\"] is not None):\n",
    "     for frame in predictions_annotations[\"instance_info\"]:\n",
    "        frame_index = frame[\"frame_id\"]-1\n",
    "        if frame_index < frame_count and (is60fps == 0 or frame_index % 2 == 0):\n",
    "            person_id = 0\n",
    "            keypoints = frames[frame_index]\n",
    "            for pose in frame[\"instances\"]:\n",
    "                pose_kpts = pose[\"keypoints\"]\n",
    "                keypoints_index = 0\n",
    "                points = []\n",
    "                confidences = []\n",
    "                kpts = []\n",
    "                for i, idx in enumerate(labels):\n",
    "                    if idx in gtLabels:\n",
    "                        common_labels.add(idx)\n",
    "                    if i < len(pose_kpts):\n",
    "                        points.append({'id': idx, 'x': pose_kpts[i][0], 'y': pose_kpts[i][1], 'confidence': pose[\"keypoint_scores\"][i]})\n",
    "                        confidences.append(pose[\"keypoint_scores\"][i])\n",
    "                        kpts.append(pose_kpts[i][0])\n",
    "                        kpts.append(pose_kpts[i][1])\n",
    "                        kpts.append(2) #visibility\n",
    "\n",
    "                keypoint = {'points': points, 'confidence': confidences, 'kpts' : kpts}\n",
    "\n",
    "                keypoints.append({'person': keypoint, 'person_id': person_id})\n",
    "                person_id += 1\n",
    "\n",
    "            frames[frame_index] = keypoints\n",
    "  else:\n",
    "    prev_frameindex = -1\n",
    "    person_id = 0\n",
    "    for pose in predictions_annotations:\n",
    "        frames, prev_frameindex, person_id, keypoints = load_alphaposeframe(pose, frames, frame_count, prev_frameindex, person_id, labels, gtLabels, keypoints, is60fps)\n",
    "\n",
    "  return frames, common_labels\n",
    "\n",
    "\n",
    "def load_annotations(labels, gtLabels, file_path, is60fps):\n",
    "    frames = defaultdict(list)\n",
    "    isExist = os.path.exists(file_path)\n",
    "    if isExist:\n",
    "      annotations = []\n",
    "      with open(file_path, 'r') as f:\n",
    "          annotations = json.load(f)\n",
    "\n",
    "          framecount = annotations['item']['slots'][0]['frame_count']\n",
    "          keypoints = defaultdict(list)\n",
    "          for person in annotations['annotations']:\n",
    "            \n",
    "            for frame_index in range(0, framecount):\n",
    "              points = []\n",
    "              if frame_index < len(person['frames']):\n",
    "                frame = person['frames'][str(frame_index)]\n",
    "                for node in frame['skeleton']['nodes']:\n",
    "                  if node['name'] in gtLabels:\n",
    "                    points.append({'id': node['name'], 'occluded' : node['occluded'], 'x' : node['x'], 'y': node['y']})\n",
    "\n",
    "              if len(points) > 0:\n",
    "                # Create a dictionary to map 'id' to its position in the order array\n",
    "                id_to_index = {id_value: index for index, id_value in enumerate(labels)}\n",
    "\n",
    "                # Sort the data based on the custom sorting key\n",
    "                sorted_data = sorted(points, key=lambda x: id_to_index.get(x['id'], float('inf')))\n",
    "                kpts = []\n",
    "                for point in sorted_data:\n",
    "                    if point['id'] in labels: #check joint is available for this technique\n",
    "                        kpts.append(point['x'])\n",
    "                        kpts.append(point['y'])\n",
    "\n",
    "                        if point[\"occluded\"] == \"false\":\n",
    "                            kpts.append(2)\n",
    "                        else:                       \n",
    "                            kpts.append(1)\n",
    "\n",
    "                index = frame_index\n",
    "                if is60fps:\n",
    "                    index = to60fps(frame_index)\n",
    "                keypoints[index].append({'person': {'points': points, 'kpts' : kpts}})\n",
    "\n",
    "        #   for frame in range(0, len(keypoints)):\n",
    "        #     frames[frame] = keypoints[frame]\n",
    "\n",
    "    return keypoints\n",
    "\n",
    "def load_data(file):\n",
    "    with open(file, 'r') as f:\n",
    "      manifest = json.load(f)\n",
    "\n",
    "    gtLabels = customutils.get_classes('configs/halpe26_classes.txt')\n",
    "    \n",
    "    names = gtLabels[:]\n",
    "    names.append('Total')\n",
    "    \n",
    "    apAll_2 = np.zeros([len(names),1])\n",
    "    ap50All_2 = np.zeros([len(names),1])\n",
    "    ap75All_2 = np.zeros([len(names),1])\n",
    "\n",
    "    names.append('Total (COCO)')\n",
    "\n",
    "    apAll = np.zeros([len(names),1])\n",
    "    ap50All = np.zeros([len(names),1])\n",
    "    ap75All = np.zeros([len(names),1])\n",
    "    pckAll = np.zeros([len(names),1])\n",
    "\n",
    "    for i in manifest['index']:\n",
    "        print('Processing ' + i['file'])\n",
    "\n",
    "        labels = customutils.get_classes(manifest['labels'])\n",
    "        is60fps = i['is60fps']\n",
    "        gt = load_annotations(labels, gtLabels, i['annotations'], is60fps)\n",
    "        predictions = i['predictions']\n",
    "        if os.path.isfile(predictions):\n",
    "            pred, labels = load_predictions(gtLabels, labels, predictions, len(gt), is60fps)\n",
    "        else:\n",
    "            pred, labels = load_prediction_files(gtLabels, labels, predictions, len(gt), is60fps)\n",
    "\n",
    "        pck, ap, ap50, ap75, ap_2, ap50_2, ap75_2 = computeMetrics(gtLabels, names, gt, pred, manifest['model'] + '_' + i['name'])\n",
    "        pckAll = (pckAll + pck)\n",
    "        apAll = (apAll + ap)\n",
    "        ap50All = (ap50All + ap50)\n",
    "        ap75All = (ap75All + ap75)\n",
    "\n",
    "    pckAll = pckAll/len(manifest['index'])\n",
    "    apAll = apAll/len(manifest['index'])\n",
    "    ap50All = ap50All/len(manifest['index'])\n",
    "    ap75All = ap75All/len(manifest['index'])\n",
    "\n",
    "    metrics = {'pckh': pckAll.flatten().tolist(), \n",
    "               'AP': apAll.flatten().tolist(),  \n",
    "               'AP0.5': ap50All.flatten().tolist(),  \n",
    "               'AP0.75': ap75All.flatten().tolist(), \n",
    "               'names': names}\n",
    "    filename = 'results/results_' +  file #manifest['model'] + '.json'\n",
    "    print('saving results to', filename)\n",
    "    customutils.writeJson(metrics,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_keypoints(gtLabels, predLabels, gt, annotations):\n",
    "    keypoints_index = 0\n",
    "    points = []\n",
    "    confidences = []\n",
    "    pose_kpts = annotations['keypoints']\n",
    "    for label in gtLabels:\n",
    "      points.append({'id': label, 'x': pose_kpts[keypoints_index], 'y': pose_kpts[keypoints_index+1], 'visibility': pose_kpts[keypoints_index+2]})\n",
    "      keypoints_index = keypoints_index + 3\n",
    "\n",
    "    # Create a dictionary to map 'id' to its position in the order array\n",
    "    id_to_index = {id_value: index for index, id_value in enumerate(predLabels)}\n",
    "\n",
    "    # Sort the data based on the custom sorting key\n",
    "    sorted_data = sorted(points, key=lambda x: id_to_index.get(x['id'], float('inf')))\n",
    "    kpts = []\n",
    "    for point in sorted_data:\n",
    "      kpts.append(point['x'])\n",
    "      kpts.append(point['y'])\n",
    "      kpts.append(point['visibility'])\n",
    "\n",
    "    gt[annotations['image_id']].append({'person': {'points': sorted_data, 'kpts' : kpts}})\n",
    "\n",
    "    return gt\n",
    "\n",
    "\n",
    "def load_alphapose_predictions(gtLabels, labels, file_path, frame_count):\n",
    "  frames = defaultdict(list)\n",
    "  common_labels = set()\n",
    "\n",
    "  with open(file_path, 'r') as f:\n",
    "    pose = json.load(f)\n",
    "\n",
    "    prev_frameindex = -1\n",
    "    person_id = 0\n",
    "    keypoints = []\n",
    "    frames, prev_frameindex, person_id, keypoints = load_alphaposeframe(pose, frames, frame_count, prev_frameindex, person_id, labels, gtLabels, keypoints)\n",
    "\n",
    "  return frames, common_labels\n",
    "\n",
    "def load_mpii():\n",
    "    with open('../data/mpii/trainval.json', 'r') as f:\n",
    "      manifest = json.load(f)\n",
    "\n",
    "def load_coco(model):\n",
    "    with open('../data/coco/annotations/person_keypoints_val2017.json', 'r') as f:\n",
    "      manifest = json.load(f)\n",
    "\n",
    "    gtLabels = customutils.get_classes('configs/coco_classes.txt')\n",
    "    \n",
    "    names = gtLabels[:]\n",
    "    names.append('Total')\n",
    "    names.append('Total (COCO)')\n",
    "\n",
    "    apAll = np.zeros([len(names),1])\n",
    "    ap50All = np.zeros([len(names),1])\n",
    "    ap75All = np.zeros([len(names),1])\n",
    "    pckAll = np.zeros([len(names),1])\n",
    "\n",
    "    gt = defaultdict(list)\n",
    "    predictions = defaultdict(list)\n",
    "    image_count = 0\n",
    "    for i in manifest['annotations']:\n",
    "      image_name = str(i['image_id']).zfill(12)\n",
    "      image = image_name + '.jpg'\n",
    "      image_count += 1\n",
    "\n",
    "      if model == 'alphapose':\n",
    "        labels = customutils.get_classes('configs/halpe26_classes.txt')\n",
    "\n",
    "        gt = load_keypoints(gtLabels, labels, gt, i)\n",
    "        predictions_file = '../data/output/alphapose/coco/val2017/' + image_name + '/alphapose-results.json'\n",
    "        # pred = load_alphapose_predictions(gtLabels, labels, file_path, 1)\n",
    "        if os.path.isfile(predictions_file):\n",
    "          pred, labels = load_predictions(gtLabels, labels, predictions_file, np.inf)\n",
    "        else:\n",
    "          pred, labels = load_prediction_files(gtLabels, labels, predictions_file, np.inf)\n",
    "\n",
    "        for k,v in pred.items():\n",
    "           predictions[k] = v\n",
    "\n",
    "    pck, ap, ap50, ap75, ap_2, ap50_2, ap75_2 = computeMetrics(gtLabels, names, gt, predictions, model + '_' + image_name)\n",
    "    pckAll = (pckAll + pck)\n",
    "    apAll = (apAll + ap)\n",
    "    ap50All = (ap50All + ap50)\n",
    "    ap75All = (ap75All + ap75)\n",
    "\n",
    "    pckAll = pckAll/image_count\n",
    "    apAll = apAll/image_count\n",
    "    ap50All = ap50All/image_count\n",
    "    ap75All = ap75All/image_count\n",
    "        \n",
    "    metrics = {'pckh': pckAll.flatten().tolist(), \n",
    "               'AP': apAll.flatten().tolist(),  \n",
    "               'AP0.5': ap50All.flatten().tolist(),  \n",
    "               'AP0.75': ap75All.flatten().tolist(),  \n",
    "               'AP_2': ap_2.flatten().tolist(),  \n",
    "               'AP0.5_2': ap50_2.flatten().tolist(),  \n",
    "               'AP0.75_2': ap75_2.flatten().tolist(), \n",
    "               'names': names}\n",
    "    filename = 'results/results_coco_' +  model + '.json'\n",
    "    print('saving results to', filename)\n",
    "    customutils.writeJson(metrics,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_coco('alphapose')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Athletics_Mixed_Tokyo_2020_20_1.avi\n",
      "saving results to results/results_pckh_vitpose_Athletics_Mixed_Tokyo_2020_20_1.json\n",
      "Processing Triathlon_Women_Tokyo_2020_29.avi\n",
      "saving results to results/results_pckh_vitpose_Triathlon_Women_Tokyo_2020_29.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_1.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_10000m_Oregon_2022_1.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_2.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_10000m_Oregon_2022_2.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_23.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_10000m_Oregon_2022_23.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_25.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_10000m_Oregon_2022_25.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_28.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_10000m_Oregon_2022_28.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_38.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_10000m_Oregon_2022_38.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_46.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_10000m_Oregon_2022_46.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_49.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_10000m_Oregon_2022_49.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_5.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_10000m_Oregon_2022_5.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_18.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_5000m_Oregon_2022_18.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_20.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_5000m_Oregon_2022_20.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_21.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_5000m_Oregon_2022_21.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_26.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_5000m_Oregon_2022_26.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_3.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_5000m_Oregon_2022_3.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_9.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Men_5000m_Oregon_2022_9.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_10.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Women_10000m_Oregon_2022_10.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_2.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Women_10000m_Oregon_2022_2.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_32.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Women_10000m_Oregon_2022_32.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_35.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Women_10000m_Oregon_2022_35.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_43.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Women_10000m_Oregon_2022_43.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_46.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Women_10000m_Oregon_2022_46.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_5.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Women_10000m_Oregon_2022_5.json\n",
      "Processing World_Athletics_Women_5000m_Oregon_2022_24.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Women_5000m_Oregon_2022_24.json\n",
      "Processing World_Athletics_Women_5000m_Oregon_2022_26.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Women_5000m_Oregon_2022_26.json\n",
      "Processing World_Athletics_Women_5000m_Oregon_2022_28.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Women_5000m_Oregon_2022_28.json\n",
      "Processing World_Athletics_Women_5000m_Oregon_2022_7.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Women_5000m_Oregon_2022_7.json\n",
      "Processing World_Athletics_Women_Marathon_Oregon_2022_2.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Women_Marathon_Oregon_2022_2.json\n",
      "Processing World_Athletics_Women_Marathon_Oregon_2022_8.mp4\n",
      "saving results to results/results_pckh_vitpose_World_Athletics_Women_Marathon_Oregon_2022_8.json\n",
      "saving results to results/results_manifest_vitpose.json\n",
      "Processing Athletics_Mixed_Tokyo_2020_20_1.avi\n",
      "saving results to results/results_pckh_alphapose_Athletics_Mixed_Tokyo_2020_20_1.json\n",
      "Processing Triathlon_Women_Tokyo_2020_29.avi\n",
      "saving results to results/results_pckh_alphapose_Triathlon_Women_Tokyo_2020_29.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_1.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_10000m_Oregon_2022_1.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_2.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_10000m_Oregon_2022_2.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_23.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_10000m_Oregon_2022_23.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_25.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_10000m_Oregon_2022_25.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_28.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_10000m_Oregon_2022_28.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_38.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_10000m_Oregon_2022_38.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_46.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_10000m_Oregon_2022_46.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_49.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_10000m_Oregon_2022_49.json\n",
      "Processing World_Athletics_Men_10000m_Oregon_2022_5.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_10000m_Oregon_2022_5.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_18.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_5000m_Oregon_2022_18.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_20.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_5000m_Oregon_2022_20.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_21.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_5000m_Oregon_2022_21.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_26.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_5000m_Oregon_2022_26.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_3.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_5000m_Oregon_2022_3.json\n",
      "Processing World_Athletics_Men_5000m_Oregon_2022_9.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_5000m_Oregon_2022_9.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_10.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Women_10000m_Oregon_2022_10.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_2.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Women_10000m_Oregon_2022_2.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_32.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Women_10000m_Oregon_2022_32.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_35.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Women_10000m_Oregon_2022_35.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_43.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Women_10000m_Oregon_2022_43.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_46.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Women_10000m_Oregon_2022_46.json\n",
      "Processing World_Athletics_Women_10000m_Oregon_2022_5.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Women_10000m_Oregon_2022_5.json\n",
      "Processing World_Athletics_Women_5000m_Oregon_2022_24.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Women_5000m_Oregon_2022_24.json\n",
      "Processing World_Athletics_Women_5000m_Oregon_2022_26.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Women_5000m_Oregon_2022_26.json\n",
      "Processing World_Athletics_Women_5000m_Oregon_2022_28.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Women_5000m_Oregon_2022_28.json\n",
      "Processing World_Athletics_Women_5000m_Oregon_2022_7.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Women_5000m_Oregon_2022_7.json\n",
      "Processing World_Athletics_Women_Marathon_Oregon_2022_2.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Women_Marathon_Oregon_2022_2.json\n",
      "Processing World_Athletics_Women_Marathon_Oregon_2022_8.mp4\n",
      "saving results to results/results_pckh_alphapose_World_Athletics_Women_Marathon_Oregon_2022_8.json\n",
      "saving results to results/results_manifest_alphapose.json\n"
     ]
    }
   ],
   "source": [
    "#load_data(\"manifest_vitpose.json\")\n",
    "load_data(\"manifest_openpose.json\")\n",
    "#load_data(\"manifest_alphapose.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing clip_tri_1.mp4\n",
      "saving results to results/results_pckh_openpose_clip_tri_1.json\n",
      "Processing clip_tri_3.mp4\n",
      "saving results to results/results_pckh_openpose_clip_tri_3.json\n",
      "Processing clip_marathon_1.mp4\n",
      "saving results to results/results_pckh_openpose_clip_marathon_1.json\n",
      "Processing clip_10k_2.mp4\n",
      "saving results to results/results_pckh_openpose_clip_10k_2.json\n",
      "Processing short.mp4\n",
      "saving results to results/results_pckh_openpose_short.json\n",
      "saving results to results/results_openpose.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "load_data(\"vitpose.json\")\n",
    "load_data(\"rtmpose_cocowb.json\")\n",
    "load_data(\"openpose.json\")\n",
    "load_data(\"alphapose_halpe.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
