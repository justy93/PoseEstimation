{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def get_classes(classes_path):\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "def getIDByName(labels, name):\n",
    "    return labels.index(name)\n",
    "\n",
    "def get_keypointconstants(classes_path):\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [float(c.strip()) for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "def getHeadSize(x1,y1,x2,y2):\n",
    "    headSize = 0.6*np.linalg.norm(np.subtract([x2,y2],[x1,y1]))\n",
    "    return headSize\n",
    "\n",
    "def getTopPoint(points):\n",
    "    point = []\n",
    "    for i in range(len(points)):\n",
    "        if (points[i][\"id\"] is not None and points[i][\"id\"] == \"Nose\"): # if joint id matches\n",
    "            point = points[i]\n",
    "            break\n",
    "\n",
    "    return point\n",
    "\n",
    "def getPointbyID(points,id):\n",
    "\n",
    "    point = []\n",
    "    for i in range(len(points)):\n",
    "        if (points[i][\"id\"] is not None and points[i][\"id\"] == id): # if joint id matches\n",
    "            point = points[i]\n",
    "            break\n",
    "\n",
    "    return point\n",
    "\n",
    "def writeJson(val,fname):\n",
    "  with open(fname, 'w') as data_file:\n",
    "    json.dump(val, data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEYPOINT_CONSTANTS = get_keypointconstants('configs/keypointconstant.txt')\n",
    "LABELS_COCO = get_classes('configs/coco_classes.txt')\n",
    "\n",
    "def get_bb(points):\n",
    "    x_values = [item[\"x\"] for item in points]\n",
    "    y_values = [item[\"y\"] for item in points]\n",
    "\n",
    "    # Get the minimum x and y values\n",
    "    min_x = min(x_values)\n",
    "    max_x = max(x_values)\n",
    "    min_y = min(y_values)\n",
    "    max_y = max(y_values)\n",
    "\n",
    "    return [min_x, min_y], [min_x, max_y], [max_x, max_y], [max_x, min_y]\n",
    "        \n",
    "        \n",
    "def compute_area(bounding_box):\n",
    "    box_width = bounding_box[2][0] - bounding_box[0][0]\n",
    "    box_height = bounding_box[2][1] - bounding_box[0][1]\n",
    "\n",
    "    return box_width*box_height\n",
    "\n",
    "def compute_scale(image_size, bounding_box):\n",
    "    # Get the width and height of the image\n",
    "    image_width, image_height = image_size\n",
    "\n",
    "    # Calculate the width and height of the bounding box\n",
    "    box_width = bounding_box[2][0] - bounding_box[0][0]\n",
    "    box_height = bounding_box[2][1] - bounding_box[0][1]\n",
    "\n",
    "    # Calculate the scale factors\n",
    "    scale_width = box_width / image_width\n",
    "    scale_height = box_height / image_height\n",
    "\n",
    "    # Choose the minimum scale factor\n",
    "    scale = min(scale_width, scale_height)\n",
    "\n",
    "    return scale\n",
    "\n",
    "def compute_oks(joint, d, area, visibility):\n",
    "    k = KEYPOINT_CONSTANTS[joint]\n",
    "    \n",
    "    # Compute the exponential part of the equation\n",
    "    exp_vector = np.exp(-(d**2) / (2 * (area) * (k**2)))\n",
    "    # The numerator expression\n",
    "    numerator = np.dot(exp_vector, int(visibility))\n",
    "    # The denominator expression\n",
    "    denominator = np.sum(int(visibility))\n",
    "    return numerator / denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeDistOks(gtLabels, gtFrames, prFrames):\n",
    "    assert len(gtFrames) == len(prFrames)\n",
    "\n",
    "    nJoints = len(gtLabels)\n",
    "    distAll = {}\n",
    "    dist = {}\n",
    "    ious = {}\n",
    "    iousAll = {}\n",
    "    for joint in range(nJoints):\n",
    "        distAll[joint] = np.zeros([0,0])\n",
    "        iousAll[joint] = []\n",
    "\n",
    "    for imgidx in range(len(gtFrames)):\n",
    "        # ground truth\n",
    "        gtFrame = gtFrames[imgidx]\n",
    "        # prediction\n",
    "        detFrame = prFrames[imgidx]\n",
    "        prFramesLen = len(detFrame)\n",
    "        dist = np.ones((len(gtFrame), max(prFramesLen,1), nJoints)) * np.inf\n",
    "        ious = np.zeros((len(gtFrame), max(prFramesLen,1), nJoints))\n",
    "        \n",
    "        for personGT in range(len(gtFrames[imgidx])):\n",
    "            rectGT = gtFrames[imgidx][personGT]\n",
    "            # if no poses predicted, initialise\n",
    "            if prFramesLen == 0:\n",
    "                for pidx in range(nJoints):\n",
    "                    dist[personGT, 0, pidx] = np.inf\n",
    "            else:\n",
    "                # compute distance between each detection and ground truth object\n",
    "                for personDT in range(prFramesLen):\n",
    "                    rectPr = prFrames[imgidx][personDT]\n",
    "                    if (\"person\" in rectGT.keys() and rectGT[\"person\"] is not None):\n",
    "                        pointsGT = rectGT[\"person\"][\"points\"]\n",
    "                        pointsPr = rectPr[\"person\"][\"points\"]\n",
    "                        bb = get_bb(pointsGT)\n",
    "                        area = compute_area(bb)\n",
    "                        for pidx, idxGT in enumerate(gtLabels):\n",
    "                            keypointGT = getPointbyID(pointsGT,idxGT)\n",
    "                            pointGT = [keypointGT[\"x\"],keypointGT[\"y\"]]\n",
    "                            idxGT = keypointGT[\"id\"]\n",
    "                            #idx = getIDByName(gtLabels, idxGT)\n",
    "                            p = getPointbyID(pointsPr,idxGT)\n",
    "                            if (len(p) > 0 and\n",
    "                                isinstance(p[\"x\"], (int, float)) and\n",
    "                                isinstance(p[\"y\"], (int, float)) and \n",
    "                                p[\"x\"] > 0 and\n",
    "                                p[\"y\"] > 0):\n",
    "                                pointPr = [p[\"x\"],p[\"y\"]]\n",
    "                                visible = keypointGT[\"occluded\"] == \"false\"\n",
    "                                # compute distance between GT and prediction\n",
    "                                d = np.linalg.norm(np.subtract(pointGT,pointPr))\n",
    "                                oks = compute_oks(pidx, d, area, visible)\n",
    "                                # compute head size for distance normalization\n",
    "                                head = getPointbyID(pointsGT,\"Head\")\n",
    "                                neck = getPointbyID(pointsGT,\"Nose\")\n",
    "                                headSize = getHeadSize(head[\"x\"],head[\"y\"], neck[\"x\"],neck[\"y\"])\n",
    "                                # normalize distance\n",
    "                                dNorm = d/headSize\n",
    "                            else:\n",
    "                                dNorm = np.inf\n",
    "                                oks = 0\n",
    "\n",
    "                            dist[personGT, personDT, pidx] = dNorm\n",
    "                            ious[personGT, personDT, pidx] = oks\n",
    "\n",
    "\n",
    "        #find matching detection (minimum distance) for each ground truth\n",
    "        for personGT in range(len(gtFrames[imgidx])):\n",
    "            min_dist = np.inf\n",
    "            if prFramesLen == 0:\n",
    "                minPersonDT = 0\n",
    "            for personDT in range(len(prFrames[imgidx])):\n",
    "                total_dist = 0\n",
    "                for idx in range(nJoints):\n",
    "                    if dist[personGT, personDT, idx] != np.inf:\n",
    "                        total_dist += dist[personGT, personDT, idx]\n",
    "                if total_dist < min_dist:\n",
    "                    min_dist = total_dist\n",
    "                    minPersonDT = personDT\n",
    "        \n",
    "            for idx in range(nJoints):\n",
    "                #print(str(dist[personGT, minPersonDT, idx]) + ' ' + str(personGT) + ' ' + str(minPersonDT) + ' ' + str(idx))\n",
    "                distAll[idx] = np.append(distAll[idx],[[dist[personGT, minPersonDT, idx]]])\n",
    "                iousAll[idx].append(ious[personGT, minPersonDT, idx])\n",
    "\n",
    "\n",
    "    return distAll, iousAll\n",
    "\n",
    "def computeAP(labels, iousAll, thresh):\n",
    "\n",
    "    ap = np.zeros([len(iousAll)+2,1])\n",
    "    nCorrect = 0\n",
    "    nTotal = 0\n",
    "    nCorrectCoco = 0\n",
    "    nTotalCoco = 0\n",
    "    for pidx in range(len(iousAll)):\n",
    "        if len(iousAll[pidx]) == 0:\n",
    "            print (pidx)\n",
    "            ap[pidx,0] = np.inf\n",
    "        else:\n",
    "            threshArr = np.ones(len(iousAll[pidx]))*thresh\n",
    "            idxs = np.argwhere(iousAll[pidx] >= threshArr)\n",
    "            oks = 100.0*len(idxs)/len(iousAll[pidx])\n",
    "            ap[pidx,0] = oks\n",
    "            nCorrect += len(idxs)\n",
    "            nTotal   += len(iousAll[pidx])\n",
    "            if labels[pidx] in LABELS_COCO:\n",
    "                nCorrectCoco += len(idxs)\n",
    "                nTotalCoco   += len(iousAll[pidx])\n",
    "    ap[len(iousAll),0] = 100.0*nCorrect/nTotal\n",
    "    ap[len(iousAll)+1,0] = 100.0*nCorrectCoco/nTotalCoco\n",
    "\n",
    "    return ap\n",
    "\n",
    "def computePCK(labels, distAll, distThresh):\n",
    "\n",
    "    pckAll = np.zeros([len(distAll)+2,1])\n",
    "    nCorrect = 0\n",
    "    nTotal = 0\n",
    "    nCorrectCoco = 0\n",
    "    nTotalCoco = 0\n",
    "    for pidx in range(len(distAll)):\n",
    "        idxs = np.argwhere(distAll[pidx] <= distThresh)\n",
    "        pck = 100.0*len(idxs)/len(distAll[pidx])\n",
    "        pckAll[pidx,0] = pck\n",
    "        nCorrect += len(idxs)\n",
    "        nTotal   += len(distAll[pidx])\n",
    "        if labels[pidx] in LABELS_COCO:\n",
    "            nCorrectCoco += len(idxs)\n",
    "            nTotalCoco   += len(distAll[pidx])\n",
    "    pckAll[len(distAll),0] = 100.0*nCorrect/nTotal\n",
    "    pckAll[len(distAll)+1,0] = 100.0*nCorrectCoco/nTotalCoco\n",
    "\n",
    "    return pckAll\n",
    "\n",
    "\n",
    "def computeMetrics(gtLabels, names, gtFramesAll, prFramesAll, file):\n",
    "\n",
    "    distThresh = 0.5\n",
    "\n",
    "    # compute distances\n",
    "    distAll, oks = computeDistOks(gtLabels, gtFramesAll, prFramesAll)\n",
    "\n",
    "    ap50 = computeAP(gtLabels, oks, distThresh)\n",
    "    ap = np.copy(ap50)\n",
    "    for i in range(9):\n",
    "        distThresh += 0.05\n",
    "        ap += computeAP(gtLabels, oks, distThresh)\n",
    "    ap75 = computeAP(gtLabels, oks, 0.75)\n",
    "    ap = ap/10\n",
    "\n",
    "    # compute PCK metric\n",
    "    pckAll = computePCK(gtLabels, distAll, distThresh)\n",
    "    metrics = {'pckh': pckAll.flatten().tolist(), \n",
    "               'AP': ap.flatten().tolist(),  \n",
    "               'AP0.5': ap50.flatten().tolist(),  \n",
    "               'AP0.75': ap75.flatten().tolist(),  \n",
    "               'names': names}\n",
    "    filename = 'results/results_pckh_' + file + '.json'\n",
    "    print('saving results to', filename)\n",
    "    writeJson(metrics,filename)\n",
    "\n",
    "    return pckAll, ap, ap50, ap75\n",
    "\n",
    "\n",
    "#load_data(\"test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, argparse, json, re\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_prediction_files(gtLabels, labels, file_path, frame_count):\n",
    "    frames = defaultdict(list)\n",
    "    common_labels = set()\n",
    "\n",
    "    for filename in os.listdir(file_path):\n",
    "        if filename.endswith('.json'):\n",
    "            full_file = os.path.join(file_path, filename)\n",
    "            with open(full_file, 'r') as f:            \n",
    "                pattern = '([0-9]*)([_a-z]*)\\.json$'\n",
    "                result = re.search(pattern, filename)\n",
    "                frame_index = int(result.groups(0)[0])\n",
    "                if frame_index < frame_count:\n",
    "                    predictions_annotations = json.load(f)\n",
    "                    person_id = 0\n",
    "                    for pose in predictions_annotations[\"people\"]:\n",
    "                        keypoints = frames[frame_index]\n",
    "                        pose_kpts = pose[\"pose_keypoints_2d\"]\n",
    "                        keypoints_index = 0\n",
    "                        points = []\n",
    "                        confidences = []\n",
    "                        for label in labels:\n",
    "                            if label in gtLabels:\n",
    "                                common_labels.add(label)\n",
    "                                if keypoints_index < len(pose_kpts):\n",
    "                                    points.append({'id': label, 'x': pose_kpts[keypoints_index], 'y': pose_kpts[keypoints_index+1], 'confidence': pose_kpts[keypoints_index+2]})\n",
    "                                    confidences.append(pose_kpts[keypoints_index+2])\n",
    "                            keypoints_index = keypoints_index + 3\n",
    "\n",
    "                        keypoint = {'points': points, 'confidence': confidences}\n",
    "\n",
    "                        keypoints.append({'person': keypoint, 'person_id': person_id})\n",
    "                        person_id += 1\n",
    "\n",
    "                        frames[frame_index] = keypoints\n",
    "\n",
    "\n",
    "    return frames, common_labels\n",
    "\n",
    "\n",
    "\n",
    "def load_predictions(gtLabels, labels, file_path, frame_count):\n",
    "  frames = defaultdict(list)\n",
    "  common_labels = set()\n",
    "\n",
    "  with open(file_path, 'r') as f:\n",
    "      predictions_annotations = json.load(f)\n",
    "\n",
    "\n",
    "  if (\"instance_info\" in predictions_annotations and predictions_annotations[\"instance_info\"] is not None):\n",
    "     for frame in predictions_annotations[\"instance_info\"]:\n",
    "        frame_index = frame[\"frame_id\"]-1\n",
    "        if frame_index < frame_count:\n",
    "            person_id = 0\n",
    "            keypoints = frames[frame_index]\n",
    "            for pose in frame[\"instances\"]:\n",
    "                pose_kpts = pose[\"keypoints\"]\n",
    "                keypoints_index = 0\n",
    "                points = []\n",
    "                confidences = []\n",
    "                for i, idx in enumerate(labels):\n",
    "                    if idx in gtLabels:\n",
    "                        common_labels.add(idx)\n",
    "                    if i < len(pose_kpts):\n",
    "                        points.append({'id': idx, 'x': pose_kpts[i][0], 'y': pose_kpts[i][1], 'confidence': pose[\"keypoint_scores\"][i]})\n",
    "                        confidences.append(pose[\"keypoint_scores\"][i])\n",
    "\n",
    "                keypoint = {'points': points, 'confidence': confidences}\n",
    "\n",
    "                keypoints.append({'person': keypoint, 'person_id': person_id})\n",
    "                person_id += 1\n",
    "\n",
    "            frames[frame_index] = keypoints\n",
    "  else:\n",
    "    prev_frameindex = -1\n",
    "    person_id = 0\n",
    "    for pose in predictions_annotations:\n",
    "        if (\"image_id\" in pose and pose[\"image_id\"] is not None):\n",
    "            frame_id = pose[\"image_id\"]\n",
    "        else:\n",
    "           frame_id = pose\n",
    "        frame_index = int(frame_id.replace(\".jpg\", \"\"))\n",
    "        if prev_frameindex == frame_index:\n",
    "            person_id += 1\n",
    "        else:\n",
    "            person_id = 0\n",
    "        if frame_index < frame_count:\n",
    "            keypoints = frames[frame_index]\n",
    "            pose_kpts = pose[\"keypoints\"]\n",
    "            keypoints_index = 0\n",
    "            points = []\n",
    "            confidences = []\n",
    "            for label in labels:\n",
    "                if keypoints_index < len(pose_kpts):\n",
    "                    points.append({'id': label, 'x': pose_kpts[keypoints_index], 'y': pose_kpts[keypoints_index+1], 'confidence': pose_kpts[keypoints_index+2]})\n",
    "                    confidences.append(pose_kpts[keypoints_index+2])\n",
    "                    keypoints_index = keypoints_index + 3\n",
    "\n",
    "            keypoint = {'points': points, 'confidence': confidences}\n",
    "\n",
    "            keypoints.append({'person': keypoint, 'person_id': person_id })\n",
    "\n",
    "            frames[frame_index] = keypoints\n",
    "        prev_frameindex = frame_index\n",
    "\n",
    "  return frames, common_labels\n",
    "\n",
    "def load_annotations(labels, file_path):\n",
    "    frames = defaultdict(list)\n",
    "    isExist = os.path.exists(file_path)\n",
    "    if isExist:\n",
    "      annotations = []\n",
    "      with open(file_path, 'r') as f:\n",
    "          annotations = json.load(f)\n",
    "\n",
    "          framecount = annotations['item']['slots'][0]['frame_count']\n",
    "          keypoints = defaultdict(list)\n",
    "          for person in annotations['annotations']:\n",
    "            \n",
    "            for frame_index in range(0, framecount):\n",
    "              points = []\n",
    "              if frame_index < len(person['frames']):\n",
    "                frame = person['frames'][str(frame_index)]\n",
    "                for node in frame['skeleton']['nodes']:\n",
    "                  if node['name'] in labels:\n",
    "                    points.append({'id': node['name'], 'occluded' : node['occluded'], 'x' : node['x'], 'y': node['y']})\n",
    "\n",
    "\n",
    "              if len(points) > 0:\n",
    "                keypoints[frame_index].append({'person': {'points': points}})\n",
    "\n",
    "          for frame in range(0, len(keypoints)):\n",
    "            frames[frame] = keypoints[frame]\n",
    "\n",
    "    return frames\n",
    "\n",
    "def load_data(file):\n",
    "    with open(file, 'r') as f:\n",
    "      manifest = json.load(f)\n",
    "\n",
    "    gtLabels = get_classes('configs/halpe26_classes.txt')\n",
    "    \n",
    "    names = gtLabels[:]\n",
    "    names.append('Total')\n",
    "    names.append('Total (COCO)')\n",
    "\n",
    "    apAll = np.zeros([len(names),1])\n",
    "    ap50All = np.zeros([len(names),1])\n",
    "    ap75All = np.zeros([len(names),1])\n",
    "    pckAll = np.zeros([len(names),1])\n",
    "\n",
    "    for i in manifest['index']:\n",
    "        print('Processing ' + i['file'])\n",
    "\n",
    "        gt = load_annotations(gtLabels, i['annotations'])\n",
    "        labels = get_classes(manifest['labels'])\n",
    "        predictions = i['predictions']\n",
    "        if os.path.isfile(predictions):\n",
    "            pred, labels = load_predictions(gtLabels, labels, predictions, len(gt))\n",
    "        else:\n",
    "            pred, labels = load_prediction_files(gtLabels, labels, predictions, len(gt))\n",
    "\n",
    "        pck, ap, ap50, ap75 = computeMetrics(gtLabels, names, gt, pred, manifest['model'] + '_' + i['name'])\n",
    "        pckAll = (pckAll + pck)\n",
    "        apAll = (apAll + ap)\n",
    "        ap50All = (ap50All + ap50)\n",
    "        ap75All = (ap75All + ap75)\n",
    "\n",
    "    pckAll = pckAll/len(manifest['index'])\n",
    "    apAll = apAll/len(manifest['index'])\n",
    "    ap50All = ap50All/len(manifest['index'])\n",
    "    ap75All = ap75All/len(manifest['index'])\n",
    "    \n",
    "    metrics = {'pckh': pckAll.flatten().tolist(), \n",
    "               'AP': apAll.flatten().tolist(),  \n",
    "               'AP0.5': ap50All.flatten().tolist(),  \n",
    "               'AP0.75': ap75All.flatten().tolist(),  \n",
    "               'names': names}\n",
    "    filename = 'results/results_' +  file #manifest['model'] + '.json'\n",
    "    print('saving results to', filename)\n",
    "    writeJson(metrics,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing World_Athletics_Men_10000m_Oregon_2022_1.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1408331/1399149301.py:49: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return numerator / denominator\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving results to results/results_pckh_alphapose_World_Athletics_Men_10000m_Oregon_2022_1.json\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (27,1) (28,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/mnt/d/Justine/uni/Pose Estimation/pose_eval.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Justine/uni/Pose%20Estimation/pose_eval.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#load_data(\"manifest_vitpose.json\")\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Justine/uni/Pose%20Estimation/pose_eval.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m#load_data(\"manifest_openpose.json\")\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Justine/uni/Pose%20Estimation/pose_eval.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m load_data(\u001b[39m\"\u001b[39;49m\u001b[39mmanifest_alphapose.json\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/mnt/d/Justine/uni/Pose Estimation/pose_eval.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Justine/uni/Pose%20Estimation/pose_eval.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=159'>160</a>\u001b[0m     pred, labels \u001b[39m=\u001b[39m load_prediction_files(gtLabels, labels, predictions, \u001b[39mlen\u001b[39m(gt))\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Justine/uni/Pose%20Estimation/pose_eval.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=161'>162</a>\u001b[0m pck, ap, ap50, ap75 \u001b[39m=\u001b[39m computeMetrics(gtLabels, names, gt, pred, manifest[\u001b[39m'\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m i[\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Justine/uni/Pose%20Estimation/pose_eval.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=162'>163</a>\u001b[0m pckAll \u001b[39m=\u001b[39m (pckAll \u001b[39m+\u001b[39;49m pck)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Justine/uni/Pose%20Estimation/pose_eval.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=163'>164</a>\u001b[0m apAll \u001b[39m=\u001b[39m (apAll \u001b[39m+\u001b[39m ap)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/d/Justine/uni/Pose%20Estimation/pose_eval.ipynb#W5sdnNjb2RlLXJlbW90ZQ%3D%3D?line=164'>165</a>\u001b[0m ap50All \u001b[39m=\u001b[39m (ap50All \u001b[39m+\u001b[39m ap50)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (27,1) (28,1) "
     ]
    }
   ],
   "source": [
    "#load_data(\"manifest_vitpose.json\")\n",
    "#load_data(\"manifest_openpose.json\")\n",
    "load_data(\"manifest_alphapose.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing clip_tri_1.mp4\n",
      "saving results to results/results_pckh_openpose_clip_tri_1.json\n",
      "Processing clip_tri_3.mp4\n",
      "saving results to results/results_pckh_openpose_clip_tri_3.json\n",
      "Processing clip_marathon_1.mp4\n",
      "saving results to results/results_pckh_openpose_clip_marathon_1.json\n",
      "Processing clip_10k_2.mp4\n",
      "saving results to results/results_pckh_openpose_clip_10k_2.json\n",
      "Processing short.mp4\n",
      "saving results to results/results_pckh_openpose_short.json\n",
      "saving results to results/results_openpose.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "load_data(\"vitpose.json\")\n",
    "load_data(\"rtmpose_cocowb.json\")\n",
    "load_data(\"openpose.json\")\n",
    "load_data(\"alphapose_halpe.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
